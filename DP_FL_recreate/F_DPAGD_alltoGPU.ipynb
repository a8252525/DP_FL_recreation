{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import syft as sy\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 60\n",
    "        self.test_batch_size = 64\n",
    "        self.best_lr_list = []\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 5\n",
    "        self.save_model = False\n",
    "        self.gamma = 0.1\n",
    "        self.alpha_max = float\n",
    "        self.init_alpha_max = 0.1\n",
    "        self.epsilon = 8\n",
    "        self.clip_threshold = 0.01\n",
    "        self.split = 120\n",
    "        \n",
    "        \n",
    "        #federated arg\n",
    "        self.n_workers = 10\n",
    "        self.rounds = 20\n",
    "        self.client_data_number = 600\n",
    "        \n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "\n",
    "\n",
    "workers = connect_to_workers(n_workers=args.n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:13, 73.21it/s]\n"
     ]
    }
   ],
   "source": [
    "temp = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('~/data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle = True,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = []\n",
    "for i, (data, target) in tqdm(enumerate(temp)):\n",
    "    train_loader.append((data.to(device), target.to(device)))\n",
    "\n",
    "    \n",
    "#send data to all the client first\n",
    "train_loader_send = []\n",
    "for n in range(args.n_workers):\n",
    "    unit = len(train_loader)//args.n_workers\n",
    "    if n ==0:\n",
    "        for (data, target) in train_loader[:unit]:\n",
    "            train_loader_send.append((data.send(workers[n]), target.send(workers[n])))\n",
    "    else:\n",
    "        for (data, target) in train_loader[(n-1)*unit:n*unit]:\n",
    "            train_loader_send.append((data.send(workers[n]), target.send(workers[n])))\n",
    "\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('~/data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size,\n",
    "    pin_memory = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 34, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(34, 64, 5, 1)\n",
    "        self.fc1 = nn.Linear(20*20*64, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 20*20*64)\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# model is not exactully the same as the paper since it did not mention the unit of fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_grad(temp, model):\n",
    "    for net1,net2 in zip(model.named_parameters(),temp.named_parameters()):\n",
    "        net2[1].grad = net1[1].grad.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_max (loss_list, p_nmax, clip_threshold):\n",
    "    neg_loss_array = np.array([-x for x in loss_list])\n",
    "    noise = np.random.laplace(0, clip_threshold/p_nmax, len(neg_loss_array))\n",
    "    noisy_loss = neg_loss_array + noise\n",
    "    best_loss_index = np.argmax(noisy_loss)\n",
    "    return best_loss_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grad_noise(model, noise):\n",
    "    for i, param in enumerate(model.parameters()):\n",
    "        param.grad.add_(noise[i])\n",
    "\n",
    "def sub_grad_noise(model, noise):\n",
    "    for i, param in enumerate(model.parameters()):\n",
    "        param.grad.sub_(noise[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grad_Gaussian_noise(model, device, p_ng, clip_threshold, batch_size):\n",
    "    noise = []\n",
    "    # remembe that torch.normal(mean, std) use std \n",
    "    for param in model.parameters():\n",
    "        noise.append(torch.normal(0, clip_threshold/math.sqrt(2 * p_ng), param.grad.size(), device=device)/batch_size)\n",
    "    return noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_list(args, model, Net):\n",
    "    model_list = []\n",
    "    for i in range(args.n_workers):\n",
    "        temp = Net().to(device)\n",
    "        temp.load_state_dict(model.state_dict())\n",
    "        model_list.append(temp)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_model(args, model_list):\n",
    "    new_model_state = model_list[0].state_dict()\n",
    "    #sum the weight of the model\n",
    "    for m in model_list[1:]:\n",
    "        state_m = m.state_dict()\n",
    "        #add with new_model_state\n",
    "        \n",
    "        for key in state_m:\n",
    "            new_model_state[key]  = new_model_state[key] + state_m[key]\n",
    "\n",
    "    for key in new_model_state:\n",
    "        new_model_state[key] /=  args.n_workers\n",
    "    \n",
    "    return new_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_step_size_model(args, model, device, train_loader, p_ng):\n",
    "    \n",
    "    r = np.random.randint(920)\n",
    "    step_size_loader = train_loader[r:r+5]\n",
    "    \n",
    "    \n",
    "    best_loss = math.inf\n",
    "    best_lr = 0\n",
    "    best_model = Net().to(device)\n",
    "    \n",
    "    \n",
    "    if not args.best_lr_list:\n",
    "        args.alpha_max = min(args.alpha_max, 0.1)\n",
    "    elif len(args.best_lr_list) % 10 == 0:\n",
    "        args.alpha_max = (1+args.gamma) * max(args.best_lr_list)\n",
    "        del args.best_lr_list[:]\n",
    "\n",
    "    #while lr_index == 0, means choose the noise add on gradient again.    \n",
    "\n",
    "    noise = create_grad_Gaussian_noise(model, device, p_ng, args.clip_threshold, args.batch_size)\n",
    "    index = 0\n",
    "    args.epsilon -= p_ng\n",
    "    if args.epsilon < 0:\n",
    "        return model, p_ng\n",
    "    \n",
    "    while index == 0:\n",
    "        temp_loss_list = []\n",
    "        temp_model_list = []\n",
    "        temp_lr_list = []\n",
    "        add_grad_noise(model, noise)\n",
    "        \n",
    "        for i in np.linspace(0, args.alpha_max, 21):\n",
    "            temp = Net().to(device)\n",
    "            temp_loss = 0\n",
    "            temp.load_state_dict(model.state_dict())\n",
    "            #load_state_dict will not copy the grad, so you need to copy it here.\n",
    "            load_grad(temp, model)\n",
    "            \n",
    "\n",
    "            temp_optimizer = optim.SGD(temp.parameters(), lr=i)\n",
    "            temp_optimizer.step()\n",
    "            #optimizer will be new every time, so if you have state in optimizer, it will need load state from the old optimzer.\n",
    "\n",
    "            for (data, target) in step_size_loader:\n",
    "                data,target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                temp_loss += F.nll_loss(output, target).item()\n",
    "\n",
    "            temp_loss_list.append(temp_loss)\n",
    "            temp_model_list.append(temp)\n",
    "            temp_lr_list.append(i)\n",
    "        \n",
    "        #choose the best lr with noisy max\n",
    "        index = noisy_max(temp_loss_list, math.sqrt(2*p_nmax), args.clip_threshold)\n",
    "        args.epsilon -= p_nmax\n",
    "        if args.epsilon < 0:\n",
    "            return model, p_ng\n",
    "        \n",
    "        # if index == 0, means we need to add the noise again and cost more epsilon\n",
    "        if index == 0:\n",
    "            #delete the original noise and add new noise\n",
    "            sub_grad_noise(model, noise)\n",
    "            # create new noise, and also sub the epsilon of new noise\n",
    "            p_ng = (1+args.gamma) * p_ng\n",
    "            noise = create_grad_Gaussian_noise(model, device, p_ng, args.clip_threshold, args.batch_size)\n",
    "            args.epsilon -= (args.gamma * p_ng)\n",
    "            if args.epsilon < 0:\n",
    "                break\n",
    "        else :\n",
    "            best_model.load_state_dict(temp_model_list[index].state_dict())\n",
    "            best_loss = temp_loss_list[index]\n",
    "            best_lr = temp_lr_list[index]\n",
    "            \n",
    "    args.best_lr_list.append(best_lr)\n",
    "#     print(\"best learning rate:\", best_lr)\n",
    "#     print(\"best loss:\", best_loss)\n",
    "\n",
    "\n",
    "    return best_model, p_ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, device, model, train_loader, rounds, worker_index, p_ng):\n",
    "    \n",
    "    unit = len(train_loader)//args.n_workers\n",
    "    client_batch_number = args.client_data_number // args.batch_size\n",
    "    if worker_index == 0 and rounds == 0:\n",
    "        start = 0\n",
    "    else:\n",
    "        start = unit * worker_index + rounds * client_batch_number\n",
    "    end = start + client_batch_number\n",
    "    \n",
    "    client_data_loader = train_loader[start:end]\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(client_data_loader):\n",
    "        data,target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), args.clip_threshold)\n",
    "        # Chose the best step size(learning rate)\n",
    "        batch_best_model, p_ng = best_step_size_model(args, model, device, train_loader, p_ng)\n",
    "        if args.epsilon < 0:\n",
    "            break\n",
    "        \n",
    "        model.load_state_dict(batch_best_model.state_dict())\n",
    "        model.zero_grad()\n",
    "        #remember to zero_grad or the grad will accumlate and the model will explode\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train rounds: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\talpha_max: {:.6f}\\tepsilon: {:.2f}'.format(\n",
    "                rounds, batch_idx * args.batch_size, len(train_loader) * args.batch_size ,\n",
    "                100. * batch_idx * args.batch_size / (len(train_loader) * args.batch_size), loss.item(), args.alpha_max, args.epsilon))\n",
    "    return model, p_ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, device, model, test_loader, r_number, writer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / (len(test_loader.dataset))\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('Accuracy', accuracy,r_number)\n",
    "    writer.add_scalar('Loss', test_loss, r_number)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\tepsilon: {:.2f}\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / (len(test_loader.dataset)), args.epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is worker 0\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.313747\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.127908\talpha_max: 0.100000\tepsilon: 7.56\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.425183\talpha_max: 0.093500\tepsilon: 7.21\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.785546\talpha_max: 0.093500\tepsilon: 6.86\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.621327\talpha_max: 0.097708\tepsilon: 6.51\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.751691\talpha_max: 0.097708\tepsilon: 6.16\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.052175\talpha_max: 0.107478\tepsilon: 5.81\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.506206\talpha_max: 0.107478\tepsilon: 5.46\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.325346\talpha_max: 0.118226\tepsilon: 5.11\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.566000\talpha_max: 0.118226\tepsilon: 4.71\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.229804\talpha_max: 0.117044\tepsilon: 4.29\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.417966\talpha_max: 0.117044\tepsilon: 3.90\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.148976\talpha_max: 0.128748\tepsilon: 3.51\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.215723\talpha_max: 0.128748\tepsilon: 3.08\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.141530\talpha_max: 0.134542\tepsilon: 2.67\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.218301\talpha_max: 0.134542\tepsilon: 2.26\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.078477\talpha_max: 0.125797\tepsilon: 1.85\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.170772\talpha_max: 0.125797\tepsilon: 1.44\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.037902\talpha_max: 0.131457\tepsilon: 1.03\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.167123\talpha_max: 0.131457\tepsilon: 0.50\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.032204\talpha_max: 0.137373\tepsilon: 0.04\n",
      "Now is worker 1\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.310609\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.075225\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.135951\talpha_max: 0.135999\tepsilon: 7.23\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.946191\talpha_max: 0.135999\tepsilon: 6.88\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.148975\talpha_max: 0.142119\tepsilon: 6.53\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.993419\talpha_max: 0.142119\tepsilon: 6.13\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.655066\talpha_max: 0.156331\tepsilon: 5.76\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.348897\talpha_max: 0.156331\tepsilon: 5.35\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.219599\talpha_max: 0.146170\tepsilon: 4.96\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.320243\talpha_max: 0.146170\tepsilon: 4.58\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.644625\talpha_max: 0.160787\tepsilon: 4.19\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.214148\talpha_max: 0.160787\tepsilon: 3.80\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.180632\talpha_max: 0.176865\tepsilon: 3.41\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.187561\talpha_max: 0.176865\tepsilon: 3.02\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.070478\talpha_max: 0.184824\tepsilon: 2.63\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.243409\talpha_max: 0.184824\tepsilon: 2.24\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.039085\talpha_max: 0.172811\tepsilon: 1.86\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.110505\talpha_max: 0.172811\tepsilon: 1.47\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.034543\talpha_max: 0.180587\tepsilon: 1.08\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.110248\talpha_max: 0.180587\tepsilon: 0.64\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.019802\talpha_max: 0.198646\tepsilon: 0.23\n",
      "Now is worker 2\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.299576\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.535069\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.787311\talpha_max: 0.174808\tepsilon: 7.27\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.648979\talpha_max: 0.174808\tepsilon: 6.93\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.857815\talpha_max: 0.192289\tepsilon: 6.60\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 3.306338\talpha_max: 0.192289\tepsilon: 6.27\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.780195\talpha_max: 0.190366\tepsilon: 5.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.893683\talpha_max: 0.190366\tepsilon: 5.60\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.209185\talpha_max: 0.198933\tepsilon: 5.22\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.759858\talpha_max: 0.198933\tepsilon: 4.87\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.200438\talpha_max: 0.207885\tepsilon: 4.52\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.497346\talpha_max: 0.207885\tepsilon: 4.17\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.094434\talpha_max: 0.228673\tepsilon: 3.82\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.439241\talpha_max: 0.228673\tepsilon: 3.47\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.134385\talpha_max: 0.201233\tepsilon: 3.12\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.375620\talpha_max: 0.201233\tepsilon: 2.71\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.166600\talpha_max: 0.221356\tepsilon: 2.35\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.190814\talpha_max: 0.221356\tepsilon: 1.98\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.271801\talpha_max: 0.231317\tepsilon: 1.61\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.104637\talpha_max: 0.231317\tepsilon: 1.24\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.020646\talpha_max: 0.254448\tepsilon: 0.87\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.014478\talpha_max: 0.254448\tepsilon: 0.50\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.014996\talpha_max: 0.279893\tepsilon: 0.14\n",
      "Now is worker 3\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.315350\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.180711\talpha_max: 0.261700\tepsilon: 7.60\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.054292\talpha_max: 0.261700\tepsilon: 7.22\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.942650\talpha_max: 0.259083\tepsilon: 6.87\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.411133\talpha_max: 0.259083\tepsilon: 6.52\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.018976\talpha_max: 0.256492\tepsilon: 6.13\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.247729\talpha_max: 0.256492\tepsilon: 5.72\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.226096\talpha_max: 0.225713\tepsilon: 5.33\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.265351\talpha_max: 0.225713\tepsilon: 4.94\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.149438\talpha_max: 0.248285\tepsilon: 4.56\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.218479\talpha_max: 0.248285\tepsilon: 4.17\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.097198\talpha_max: 0.259457\tepsilon: 3.78\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.138734\talpha_max: 0.259457\tepsilon: 3.39\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.219411\talpha_max: 0.285403\tepsilon: 3.00\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.052861\talpha_max: 0.285403\tepsilon: 2.61\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.195319\talpha_max: 0.282549\tepsilon: 2.17\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.065433\talpha_max: 0.282549\tepsilon: 1.76\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.025783\talpha_max: 0.310804\tepsilon: 1.35\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.016227\talpha_max: 0.310804\tepsilon: 0.90\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.095650\talpha_max: 0.324790\tepsilon: 0.41\n",
      "Now is worker 4\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.313631\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.570148\talpha_max: 0.357269\tepsilon: 7.56\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.807686\talpha_max: 0.357269\tepsilon: 7.21\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.828432\talpha_max: 0.373346\tepsilon: 6.86\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.501048\talpha_max: 0.373346\tepsilon: 6.46\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.480464\talpha_max: 0.410681\tepsilon: 6.09\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.008630\talpha_max: 0.410681\tepsilon: 5.67\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.528863\talpha_max: 0.383987\tepsilon: 5.28\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.432073\talpha_max: 0.383987\tepsilon: 4.89\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.094733\talpha_max: 0.422385\tepsilon: 4.51\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.163001\talpha_max: 0.422385\tepsilon: 4.06\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.083123\talpha_max: 0.394930\tepsilon: 3.65\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.134132\talpha_max: 0.394930\tepsilon: 3.10\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.018381\talpha_max: 0.412702\tepsilon: 2.61\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.352336\talpha_max: 0.412702\tepsilon: 2.12\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.117093\talpha_max: 0.453972\tepsilon: 1.63\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.056285\talpha_max: 0.453972\tepsilon: 1.14\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.718064\talpha_max: 0.499370\tepsilon: 0.60\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.021394\talpha_max: 0.499370\tepsilon: 0.07\n",
      "Now is worker 5\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.311925\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.363523\talpha_max: 0.521841\tepsilon: 7.60\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.907842\talpha_max: 0.521841\tepsilon: 7.27\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.939960\talpha_max: 0.545324\tepsilon: 6.93\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.213394\talpha_max: 0.545324\tepsilon: 6.60\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.605293\talpha_max: 0.569864\tepsilon: 6.22\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.681695\talpha_max: 0.569864\tepsilon: 5.82\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.602500\talpha_max: 0.626850\tepsilon: 5.42\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.421824\talpha_max: 0.626850\tepsilon: 5.03\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.045087\talpha_max: 0.620582\tepsilon: 4.64\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.503083\talpha_max: 0.620582\tepsilon: 4.25\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.392980\talpha_max: 0.682640\tepsilon: 3.86\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.169794\talpha_max: 0.682640\tepsilon: 3.48\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.639549\talpha_max: 0.750904\tepsilon: 3.09\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.164311\talpha_max: 0.750904\tepsilon: 2.70\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.585627\talpha_max: 0.825994\tepsilon: 2.31\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.127778\talpha_max: 0.825994\tepsilon: 1.92\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.194470\talpha_max: 0.863164\tepsilon: 1.53\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.387419\talpha_max: 0.863164\tepsilon: 1.09\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.146647\talpha_max: 0.902006\tepsilon: 0.68\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.061995\talpha_max: 0.902006\tepsilon: 0.27\n",
      "Now is worker 6\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.303729\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.975111\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 7.920372\talpha_max: 0.933171\tepsilon: 7.27\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.298601\talpha_max: 0.933171\tepsilon: 6.93\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.219249\talpha_max: 0.872515\tepsilon: 6.60\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 4.078955\talpha_max: 0.872515\tepsilon: 6.27\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.658479\talpha_max: 0.959766\tepsilon: 5.88\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 10.935238\talpha_max: 0.959766\tepsilon: 5.53\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.151852\talpha_max: 1.002956\tepsilon: 5.14\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.347938\talpha_max: 1.002956\tepsilon: 4.77\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.898969\talpha_max: 0.992926\tepsilon: 4.40\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.346745\talpha_max: 0.992926\tepsilon: 4.03\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.568796\talpha_max: 1.092219\tepsilon: 3.66\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.595939\talpha_max: 1.092219\tepsilon: 3.30\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.247201\talpha_max: 1.201440\tepsilon: 2.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.215013\talpha_max: 1.201440\tepsilon: 2.56\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.273517\talpha_max: 1.189426\tepsilon: 2.19\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.377273\talpha_max: 1.189426\tepsilon: 1.82\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.424485\talpha_max: 1.308369\tepsilon: 1.42\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.828220\talpha_max: 1.308369\tepsilon: 1.03\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.144959\talpha_max: 1.295285\tepsilon: 0.64\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.158197\talpha_max: 1.295285\tepsilon: 0.25\n",
      "Now is worker 7\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.306815\talpha_max: 0.100000\tepsilon: 7.90\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.011896\talpha_max: 0.100000\tepsilon: 7.55\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.401949\talpha_max: 0.093500\tepsilon: 7.20\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.093347\talpha_max: 0.093500\tepsilon: 6.85\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.513975\talpha_max: 0.097708\tepsilon: 6.44\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.746464\talpha_max: 0.097708\tepsilon: 6.08\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.322688\talpha_max: 0.102104\tepsilon: 5.71\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.644466\talpha_max: 0.102104\tepsilon: 5.34\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.304797\talpha_max: 0.112315\tepsilon: 4.97\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.473743\talpha_max: 0.112315\tepsilon: 4.56\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.159757\talpha_max: 0.098837\tepsilon: 4.17\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.525798\talpha_max: 0.098837\tepsilon: 3.78\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.159951\talpha_max: 0.108721\tepsilon: 3.39\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.370489\talpha_max: 0.108721\tepsilon: 3.00\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.066662\talpha_max: 0.113613\tepsilon: 2.61\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.261560\talpha_max: 0.113613\tepsilon: 2.23\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.099947\talpha_max: 0.124974\tepsilon: 1.84\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.108156\talpha_max: 0.124974\tepsilon: 1.45\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.087045\talpha_max: 0.137472\tepsilon: 0.97\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.068116\talpha_max: 0.137472\tepsilon: 0.53\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.032927\talpha_max: 0.120975\tepsilon: 0.10\n",
      "Now is worker 8\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.306330\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.959711\talpha_max: 0.100000\tepsilon: 7.55\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.996986\talpha_max: 0.110000\tepsilon: 7.20\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.653111\talpha_max: 0.110000\tepsilon: 6.85\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.986106\talpha_max: 0.108900\tepsilon: 6.50\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.682050\talpha_max: 0.108900\tepsilon: 6.10\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.125198\talpha_max: 0.113801\tepsilon: 5.69\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.474240\talpha_max: 0.113801\tepsilon: 5.30\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.271474\talpha_max: 0.106403\tepsilon: 4.91\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.506163\talpha_max: 0.106403\tepsilon: 4.52\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.388730\talpha_max: 0.105339\tepsilon: 4.13\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.298433\talpha_max: 0.105339\tepsilon: 3.74\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.339343\talpha_max: 0.110080\tepsilon: 3.36\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.213391\talpha_max: 0.110080\tepsilon: 2.97\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.385929\talpha_max: 0.121088\tepsilon: 2.58\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.142443\talpha_max: 0.121088\tepsilon: 2.19\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.195514\talpha_max: 0.133196\tepsilon: 1.80\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.110578\talpha_max: 0.133196\tepsilon: 1.41\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.085939\talpha_max: 0.146516\tepsilon: 1.02\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.248316\talpha_max: 0.146516\tepsilon: 0.64\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.093196\talpha_max: 0.153109\tepsilon: 0.21\n",
      "Now is worker 9\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 2.288953\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.021620\talpha_max: 0.168420\tepsilon: 7.60\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.527420\talpha_max: 0.168420\tepsilon: 7.19\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.443924\talpha_max: 0.157473\tepsilon: 6.82\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 1.132242\talpha_max: 0.157473\tepsilon: 6.41\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 1.518191\talpha_max: 0.155898\tepsilon: 6.02\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.411867\talpha_max: 0.155898\tepsilon: 5.54\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.409424\talpha_max: 0.154339\tepsilon: 5.04\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.416618\talpha_max: 0.154339\tepsilon: 4.54\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.402967\talpha_max: 0.161284\tepsilon: 4.04\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.227147\talpha_max: 0.161284\tepsilon: 3.51\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 2.353791\talpha_max: 0.141930\tepsilon: 2.98\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.483202\talpha_max: 0.141930\tepsilon: 2.46\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.233948\talpha_max: 0.140511\tepsilon: 1.83\n",
      "Train rounds: 0 [0/60000 (0%)]\tLoss: 0.117964\talpha_max: 0.140511\tepsilon: 1.23\n",
      "Train rounds: 0 [300/60000 (0%)]\tLoss: 0.437656\talpha_max: 0.154562\tepsilon: 0.58\n",
      "\n",
      "Test set: Average loss: 0.6067, Accuracy: 8363/10000 (84%)\tepsilon: -0.03\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.548155\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.547391\talpha_max: 0.144516\tepsilon: 7.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.291231\talpha_max: 0.144516\tepsilon: 7.27\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.481431\talpha_max: 0.143070\tepsilon: 6.93\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.235134\talpha_max: 0.143070\tepsilon: 6.60\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.277011\talpha_max: 0.149509\tepsilon: 6.27\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.118901\talpha_max: 0.149509\tepsilon: 5.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.267218\talpha_max: 0.164459\tepsilon: 5.55\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.041862\talpha_max: 0.164459\tepsilon: 5.20\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.190023\talpha_max: 0.180905\tepsilon: 4.85\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.130480\talpha_max: 0.180905\tepsilon: 4.50\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.106885\talpha_max: 0.198996\tepsilon: 4.15\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.132989\talpha_max: 0.198996\tepsilon: 3.80\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.061849\talpha_max: 0.207951\tepsilon: 3.40\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.100194\talpha_max: 0.207951\tepsilon: 3.03\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.078571\talpha_max: 0.228746\tepsilon: 2.62\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.017145\talpha_max: 0.228746\tepsilon: 2.18\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.025146\talpha_max: 0.226458\tepsilon: 1.77\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.005720\talpha_max: 0.226458\tepsilon: 1.36\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.022031\talpha_max: 0.199283\tepsilon: 0.91\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.004399\talpha_max: 0.199283\tepsilon: 0.47\n",
      "Now is worker 1\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.843771\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.568630\talpha_max: 0.100000\tepsilon: 7.52\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.371495\talpha_max: 0.082500\tepsilon: 7.15\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.425502\talpha_max: 0.082500\tepsilon: 6.73\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.278433\talpha_max: 0.090750\tepsilon: 6.34\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.335171\talpha_max: 0.090750\tepsilon: 5.95\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.191731\talpha_max: 0.089843\tepsilon: 5.56\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.221884\talpha_max: 0.089843\tepsilon: 5.17\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.091903\talpha_max: 0.098827\tepsilon: 4.79\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.200747\talpha_max: 0.098827\tepsilon: 4.40\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.079451\talpha_max: 0.081532\tepsilon: 4.01\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.137825\talpha_max: 0.081532\tepsilon: 3.57\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.070261\talpha_max: 0.080717\tepsilon: 3.08\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.084853\talpha_max: 0.080717\tepsilon: 2.61\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.047216\talpha_max: 0.079910\tepsilon: 2.11\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.045377\talpha_max: 0.079910\tepsilon: 1.62\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.034636\talpha_max: 0.074715\tepsilon: 1.13\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.043147\talpha_max: 0.074715\tepsilon: 0.64\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.023589\talpha_max: 0.082187\tepsilon: 0.10\n",
      "Now is worker 2\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 1.242062\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.242083\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.408122\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.217599\talpha_max: 0.110000\tepsilon: 6.93\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.229395\talpha_max: 0.114950\tepsilon: 6.60\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.165847\talpha_max: 0.114950\tepsilon: 6.27\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.243401\talpha_max: 0.120123\tepsilon: 5.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.120137\talpha_max: 0.120123\tepsilon: 5.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.162328\talpha_max: 0.132135\tepsilon: 5.27\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.115069\talpha_max: 0.132135\tepsilon: 4.93\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.161365\talpha_max: 0.116279\tepsilon: 4.60\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.049003\talpha_max: 0.116279\tepsilon: 4.27\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.055933\talpha_max: 0.127907\tepsilon: 3.88\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.039604\talpha_max: 0.127907\tepsilon: 3.53\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.085276\talpha_max: 0.119593\tepsilon: 3.18\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.022508\talpha_max: 0.119593\tepsilon: 2.83\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.059491\talpha_max: 0.131552\tepsilon: 2.48\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.008592\talpha_max: 0.131552\tepsilon: 2.13\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.052512\talpha_max: 0.137472\tepsilon: 1.78\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.023167\talpha_max: 0.137472\tepsilon: 1.38\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.063318\talpha_max: 0.151219\tepsilon: 1.02\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.008504\talpha_max: 0.151219\tepsilon: 0.61\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.009731\talpha_max: 0.158024\tepsilon: 0.22\n",
      "Now is worker 3\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.452468\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.286510\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.332621\talpha_max: 0.173826\tepsilon: 7.27\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.199297\talpha_max: 0.173826\tepsilon: 6.93\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.235769\talpha_max: 0.181649\tepsilon: 6.55\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.101324\talpha_max: 0.181649\tepsilon: 6.20\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.191136\talpha_max: 0.199813\tepsilon: 5.85\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.080945\talpha_max: 0.199813\tepsilon: 5.50\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.053582\talpha_max: 0.208805\tepsilon: 5.15\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.089760\talpha_max: 0.208805\tepsilon: 4.76\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.022282\talpha_max: 0.183748\tepsilon: 4.34\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.029167\talpha_max: 0.183748\tepsilon: 3.96\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.019458\talpha_max: 0.202123\tepsilon: 3.57\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.011488\talpha_max: 0.202123\tepsilon: 3.18\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.013793\talpha_max: 0.222336\tepsilon: 2.79\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.013213\talpha_max: 0.222336\tepsilon: 2.40\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.008857\talpha_max: 0.244569\tepsilon: 2.01\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.005411\talpha_max: 0.244569\tepsilon: 1.57\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.003668\talpha_max: 0.201769\tepsilon: 1.16\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.005003\talpha_max: 0.201769\tepsilon: 0.75\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.004377\talpha_max: 0.210849\tepsilon: 0.28\n",
      "Now is worker 4\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.430473\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.627710\talpha_max: 0.197144\tepsilon: 7.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.189022\talpha_max: 0.197144\tepsilon: 7.27\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.286026\talpha_max: 0.206015\tepsilon: 6.90\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.094592\talpha_max: 0.206015\tepsilon: 6.55\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.187820\talpha_max: 0.226617\tepsilon: 6.20\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.090785\talpha_max: 0.226617\tepsilon: 5.85\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.081126\talpha_max: 0.224351\tepsilon: 5.50\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.059683\talpha_max: 0.224351\tepsilon: 5.15\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.073191\talpha_max: 0.209768\tepsilon: 4.75\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.035499\talpha_max: 0.209768\tepsilon: 4.34\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.030293\talpha_max: 0.138447\tepsilon: 3.95\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.009471\talpha_max: 0.138447\tepsilon: 3.56\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.016792\talpha_max: 0.114219\tepsilon: 3.18\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.007572\talpha_max: 0.114219\tepsilon: 2.74\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.020762\talpha_max: 0.087948\tepsilon: 2.33\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.007646\talpha_max: 0.087948\tepsilon: 1.92\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.009029\talpha_max: 0.082232\tepsilon: 1.51\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.005424\talpha_max: 0.082232\tepsilon: 1.10\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.008336\talpha_max: 0.058796\tepsilon: 0.69\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.005227\talpha_max: 0.058796\tepsilon: 0.28\n",
      "Now is worker 5\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.739583\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.284909\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.146847\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.191315\talpha_max: 0.110000\tepsilon: 6.93\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.116937\talpha_max: 0.121000\tepsilon: 6.60\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.119347\talpha_max: 0.121000\tepsilon: 6.27\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.045865\talpha_max: 0.113135\tepsilon: 5.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.075400\talpha_max: 0.113135\tepsilon: 5.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.046639\talpha_max: 0.118226\tepsilon: 5.27\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.062742\talpha_max: 0.118226\tepsilon: 4.93\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.067887\talpha_max: 0.130049\tepsilon: 4.56\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.036759\talpha_max: 0.130049\tepsilon: 4.21\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.024339\talpha_max: 0.128748\tepsilon: 3.83\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.029333\talpha_max: 0.128748\tepsilon: 3.46\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.015137\talpha_max: 0.141623\tepsilon: 3.09\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.049145\talpha_max: 0.141623\tepsilon: 2.72\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.016630\talpha_max: 0.140207\tepsilon: 2.35\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.013311\talpha_max: 0.140207\tepsilon: 1.94\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.010967\talpha_max: 0.123382\tepsilon: 1.50\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.012789\talpha_max: 0.123382\tepsilon: 1.09\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.009798\talpha_max: 0.135720\tepsilon: 0.68\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.010173\talpha_max: 0.135720\tepsilon: 0.27\n",
      "Now is worker 6\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.532690\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.374690\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.174470\talpha_max: 0.099000\tepsilon: 7.27\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.211761\talpha_max: 0.099000\tepsilon: 6.93\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.090211\talpha_max: 0.108900\tepsilon: 6.60\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.184223\talpha_max: 0.108900\tepsilon: 6.22\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.037164\talpha_max: 0.107811\tepsilon: 5.87\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.192682\talpha_max: 0.107811\tepsilon: 5.52\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.025984\talpha_max: 0.118592\tepsilon: 5.17\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.103859\talpha_max: 0.118592\tepsilon: 4.78\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.023497\talpha_max: 0.091316\tepsilon: 4.41\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.076665\talpha_max: 0.091316\tepsilon: 4.04\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.016015\talpha_max: 0.100448\tepsilon: 3.62\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.032660\talpha_max: 0.100448\tepsilon: 3.23\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.010470\talpha_max: 0.077345\tepsilon: 2.84\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.028463\talpha_max: 0.077345\tepsilon: 2.45\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.011895\talpha_max: 0.076571\tepsilon: 2.06\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.022741\talpha_max: 0.076571\tepsilon: 1.67\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.007848\talpha_max: 0.080017\tepsilon: 1.29\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.021858\talpha_max: 0.080017\tepsilon: 0.84\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.004264\talpha_max: 0.066014\tepsilon: 0.43\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.012428\talpha_max: 0.066014\tepsilon: 0.02\n",
      "Now is worker 7\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.492016\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.384730\talpha_max: 0.104500\tepsilon: 7.56\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.206637\talpha_max: 0.104500\tepsilon: 7.21\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.262618\talpha_max: 0.114950\tepsilon: 6.81\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.150688\talpha_max: 0.114950\tepsilon: 6.45\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.227405\talpha_max: 0.113801\tepsilon: 6.08\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.172630\talpha_max: 0.113801\tepsilon: 5.71\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.135471\talpha_max: 0.125181\tepsilon: 5.34\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.113328\talpha_max: 0.125181\tepsilon: 4.97\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.040902\talpha_max: 0.137699\tepsilon: 4.56\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.044169\talpha_max: 0.137699\tepsilon: 4.17\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.097227\talpha_max: 0.151468\tepsilon: 3.72\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.059174\talpha_max: 0.151468\tepsilon: 3.31\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.022891\talpha_max: 0.141623\tepsilon: 2.90\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.030303\talpha_max: 0.141623\tepsilon: 2.49\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.018396\talpha_max: 0.140207\tepsilon: 2.08\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.015885\talpha_max: 0.140207\tepsilon: 1.67\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.010708\talpha_max: 0.154227\tepsilon: 1.26\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.008422\talpha_max: 0.154227\tepsilon: 0.85\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.023883\talpha_max: 0.169650\tepsilon: 0.39\n",
      "Now is worker 8\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.857652\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.192744\talpha_max: 0.149292\tepsilon: 7.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.247473\talpha_max: 0.149292\tepsilon: 7.27\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.103799\talpha_max: 0.147799\tepsilon: 6.93\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.209423\talpha_max: 0.147799\tepsilon: 6.60\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.049989\talpha_max: 0.162579\tepsilon: 6.27\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.428888\talpha_max: 0.162579\tepsilon: 5.93\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.138164\talpha_max: 0.178837\tepsilon: 5.60\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.076019\talpha_max: 0.178837\tepsilon: 5.23\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.016574\talpha_max: 0.157377\tepsilon: 4.88\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.023258\talpha_max: 0.157377\tepsilon: 4.53\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.028363\talpha_max: 0.173114\tepsilon: 4.18\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.155460\talpha_max: 0.173114\tepsilon: 3.79\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.006843\talpha_max: 0.190426\tepsilon: 3.42\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.019532\talpha_max: 0.190426\tepsilon: 3.05\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.011423\talpha_max: 0.209468\tepsilon: 2.68\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.010081\talpha_max: 0.209468\tepsilon: 2.32\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.004138\talpha_max: 0.230415\tepsilon: 1.95\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.008020\talpha_max: 0.230415\tepsilon: 1.58\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.002362\talpha_max: 0.215438\tepsilon: 1.21\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.002988\talpha_max: 0.215438\tepsilon: 0.84\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.002563\talpha_max: 0.236982\tepsilon: 0.47\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.003276\talpha_max: 0.236982\tepsilon: 0.11\n",
      "Now is worker 9\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.814013\talpha_max: 0.100000\tepsilon: 7.90\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.367865\talpha_max: 0.182476\tepsilon: 7.50\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.174995\talpha_max: 0.182476\tepsilon: 7.13\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.105099\talpha_max: 0.200724\tepsilon: 6.76\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.137142\talpha_max: 0.200724\tepsilon: 6.40\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.170182\talpha_max: 0.176637\tepsilon: 5.98\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.053198\talpha_max: 0.176637\tepsilon: 5.59\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.084793\talpha_max: 0.184586\tepsilon: 5.21\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.091170\talpha_max: 0.184586\tepsilon: 4.82\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.057623\talpha_max: 0.203044\tepsilon: 4.43\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.024844\talpha_max: 0.203044\tepsilon: 4.04\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.010170\talpha_max: 0.212181\tepsilon: 3.65\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.018584\talpha_max: 0.212181\tepsilon: 3.21\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.005308\talpha_max: 0.221729\tepsilon: 2.80\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.008460\talpha_max: 0.221729\tepsilon: 2.39\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.004726\talpha_max: 0.207317\tepsilon: 1.93\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.007850\talpha_max: 0.207317\tepsilon: 1.49\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.003774\talpha_max: 0.216646\tepsilon: 1.06\n",
      "Train rounds: 1 [0/60000 (0%)]\tLoss: 0.005906\talpha_max: 0.216646\tepsilon: 0.62\n",
      "Train rounds: 1 [300/60000 (0%)]\tLoss: 0.002716\talpha_max: 0.214480\tepsilon: 0.19\n",
      "\n",
      "Test set: Average loss: 0.3192, Accuracy: 9326/10000 (93%)\tepsilon: -0.04\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.184298\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.702800\talpha_max: 0.224131\tepsilon: 7.56\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.232803\talpha_max: 0.224131\tepsilon: 7.13\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.440364\talpha_max: 0.221890\tepsilon: 6.71\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.264430\talpha_max: 0.221890\tepsilon: 6.30\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.315399\talpha_max: 0.244079\tepsilon: 5.89\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.028361\talpha_max: 0.244079\tepsilon: 5.42\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.135986\talpha_max: 0.268487\tepsilon: 4.93\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.006854\talpha_max: 0.268487\tepsilon: 4.40\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.040368\talpha_max: 0.265802\tepsilon: 3.91\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.003910\talpha_max: 0.265802\tepsilon: 3.42\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.023915\talpha_max: 0.248525\tepsilon: 2.93\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.002385\talpha_max: 0.248525\tepsilon: 2.44\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.014860\talpha_max: 0.273377\tepsilon: 1.94\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.003213\talpha_max: 0.273377\tepsilon: 1.40\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.006643\talpha_max: 0.285679\tepsilon: 0.88\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.001064\talpha_max: 0.285679\tepsilon: 0.30\n",
      "Now is worker 1\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.069119\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.420574\talpha_max: 0.100000\tepsilon: 7.56\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.074187\talpha_max: 0.110000\tepsilon: 7.21\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.210915\talpha_max: 0.110000\tepsilon: 6.86\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.046701\talpha_max: 0.114950\tepsilon: 6.51\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.093878\talpha_max: 0.114950\tepsilon: 6.16\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.096858\talpha_max: 0.126445\tepsilon: 5.81\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.066512\talpha_max: 0.126445\tepsilon: 5.43\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.022763\talpha_max: 0.139090\tepsilon: 5.06\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.028487\talpha_max: 0.139090\tepsilon: 4.64\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.010822\talpha_max: 0.114749\tepsilon: 4.25\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.012154\talpha_max: 0.114749\tepsilon: 3.82\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.006547\talpha_max: 0.119913\tepsilon: 3.29\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.010885\talpha_max: 0.119913\tepsilon: 2.82\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.005838\talpha_max: 0.131904\tepsilon: 2.36\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.003876\talpha_max: 0.131904\tepsilon: 1.90\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.004843\talpha_max: 0.145094\tepsilon: 1.44\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.004549\talpha_max: 0.145094\tepsilon: 0.98\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.003397\talpha_max: 0.159604\tepsilon: 0.51\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.003575\talpha_max: 0.159604\tepsilon: 0.05\n",
      "Now is worker 2\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.370027\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.201349\talpha_max: 0.175564\tepsilon: 7.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.128336\talpha_max: 0.175564\tepsilon: 7.22\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.150201\talpha_max: 0.193120\tepsilon: 6.87\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.040678\talpha_max: 0.193120\tepsilon: 6.47\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.045256\talpha_max: 0.169946\tepsilon: 6.10\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.019296\talpha_max: 0.169946\tepsilon: 5.70\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.011833\talpha_max: 0.186940\tepsilon: 5.25\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.020280\talpha_max: 0.186940\tepsilon: 4.79\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.005855\talpha_max: 0.195353\tepsilon: 4.26\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.065306\talpha_max: 0.195353\tepsilon: 3.77\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.045199\talpha_max: 0.204144\tepsilon: 3.27\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.040230\talpha_max: 0.204144\tepsilon: 2.73\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.007385\talpha_max: 0.224558\tepsilon: 2.21\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.007839\talpha_max: 0.224558\tepsilon: 1.68\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.003649\talpha_max: 0.197611\tepsilon: 1.16\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.002605\talpha_max: 0.197611\tepsilon: 0.63\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.002471\talpha_max: 0.217372\tepsilon: 0.11\n",
      "Now is worker 3\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.358246\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.138582\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.236060\talpha_max: 0.191288\tepsilon: 7.27\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.266104\talpha_max: 0.191288\tepsilon: 6.93\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.097921\talpha_max: 0.189375\tepsilon: 6.56\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.044977\talpha_max: 0.189375\tepsilon: 6.21\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.095539\talpha_max: 0.197897\tepsilon: 5.86\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.040089\talpha_max: 0.197897\tepsilon: 5.51\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.032894\talpha_max: 0.195918\tepsilon: 5.16\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.013449\talpha_max: 0.195918\tepsilon: 4.81\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.020482\talpha_max: 0.183183\tepsilon: 4.46\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.018747\talpha_max: 0.183183\tepsilon: 4.02\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.005787\talpha_max: 0.201501\tepsilon: 3.59\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.007592\talpha_max: 0.201501\tepsilon: 3.08\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.002432\talpha_max: 0.210569\tepsilon: 2.62\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.006186\talpha_max: 0.210569\tepsilon: 2.16\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.002011\talpha_max: 0.220044\tepsilon: 1.63\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.005036\talpha_max: 0.220044\tepsilon: 1.14\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.004916\talpha_max: 0.193639\tepsilon: 0.65\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.005115\talpha_max: 0.193639\tepsilon: 0.16\n",
      "Now is worker 4\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.632282\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.232685\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.079245\talpha_max: 0.104500\tepsilon: 7.23\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.068420\talpha_max: 0.104500\tepsilon: 6.88\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.034831\talpha_max: 0.109203\tepsilon: 6.53\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.047688\talpha_max: 0.109203\tepsilon: 6.18\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.023475\talpha_max: 0.078080\tepsilon: 5.83\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.035303\talpha_max: 0.078080\tepsilon: 5.48\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.012781\talpha_max: 0.081593\tepsilon: 5.13\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.024560\talpha_max: 0.081593\tepsilon: 4.78\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.013999\talpha_max: 0.085265\tepsilon: 4.43\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.042395\talpha_max: 0.085265\tepsilon: 4.08\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.013512\talpha_max: 0.089102\tepsilon: 3.64\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.016937\talpha_max: 0.089102\tepsilon: 3.25\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.009248\talpha_max: 0.088211\tepsilon: 2.86\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.010924\talpha_max: 0.088211\tepsilon: 2.42\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.006880\talpha_max: 0.092180\tepsilon: 2.01\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.008372\talpha_max: 0.092180\tepsilon: 1.55\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.005155\talpha_max: 0.101399\tepsilon: 1.12\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.008313\talpha_max: 0.101399\tepsilon: 0.68\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.004508\talpha_max: 0.111538\tepsilon: 0.21\n",
      "Now is worker 5\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.570179\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.220361\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.168845\talpha_max: 0.116558\tepsilon: 7.27\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.122784\talpha_max: 0.116558\tepsilon: 6.93\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.099628\talpha_max: 0.128213\tepsilon: 6.60\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.075287\talpha_max: 0.128213\tepsilon: 6.22\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.033722\talpha_max: 0.133983\tepsilon: 5.84\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.046020\talpha_max: 0.133983\tepsilon: 5.47\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.024282\talpha_max: 0.147381\tepsilon: 5.10\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.026186\talpha_max: 0.147381\tepsilon: 4.73\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.009544\talpha_max: 0.154013\tepsilon: 4.36\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.016916\talpha_max: 0.154013\tepsilon: 3.99\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.013962\talpha_max: 0.144003\tepsilon: 3.63\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.027252\talpha_max: 0.144003\tepsilon: 3.26\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.006476\talpha_max: 0.150483\tepsilon: 2.89\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.008303\talpha_max: 0.150483\tepsilon: 2.52\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.004842\talpha_max: 0.165531\tepsilon: 2.11\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.004018\talpha_max: 0.165531\tepsilon: 1.72\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.005144\talpha_max: 0.182084\tepsilon: 1.33\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.002471\talpha_max: 0.182084\tepsilon: 0.90\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.003976\talpha_max: 0.180263\tepsilon: 0.49\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.001577\talpha_max: 0.180263\tepsilon: 0.08\n",
      "Now is worker 6\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.568476\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.732467\talpha_max: 0.158632\tepsilon: 7.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.278470\talpha_max: 0.158632\tepsilon: 7.27\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.141576\talpha_max: 0.174495\tepsilon: 6.93\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.173046\talpha_max: 0.174495\tepsilon: 6.60\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.092821\talpha_max: 0.191944\tepsilon: 6.27\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.126857\talpha_max: 0.191944\tepsilon: 5.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.031893\talpha_max: 0.211139\tepsilon: 5.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.033700\talpha_max: 0.211139\tepsilon: 5.27\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.024192\talpha_max: 0.232253\tepsilon: 4.93\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.347912\talpha_max: 0.232253\tepsilon: 4.60\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.038407\talpha_max: 0.255478\tepsilon: 4.27\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.064808\talpha_max: 0.255478\tepsilon: 3.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.454880\talpha_max: 0.266974\tepsilon: 3.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.007634\talpha_max: 0.266974\tepsilon: 3.22\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.017945\talpha_max: 0.278988\tepsilon: 2.87\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.010428\talpha_max: 0.278988\tepsilon: 2.52\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.025376\talpha_max: 0.291543\tepsilon: 2.17\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.013720\talpha_max: 0.291543\tepsilon: 1.82\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.005125\talpha_max: 0.320697\tepsilon: 1.47\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.001737\talpha_max: 0.320697\tepsilon: 1.12\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.002521\talpha_max: 0.317490\tepsilon: 0.77\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.000957\talpha_max: 0.317490\tepsilon: 0.42\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.001843\talpha_max: 0.349239\tepsilon: 0.07\n",
      "Now is worker 7\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.285935\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.203847\talpha_max: 0.345746\tepsilon: 7.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.518052\talpha_max: 0.345746\tepsilon: 7.27\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.284269\talpha_max: 0.380321\tepsilon: 6.93\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.316073\talpha_max: 0.380321\tepsilon: 6.56\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.095029\talpha_max: 0.292847\tepsilon: 6.21\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.065413\talpha_max: 0.292847\tepsilon: 5.86\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.052845\talpha_max: 0.306025\tepsilon: 5.51\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.091847\talpha_max: 0.306025\tepsilon: 5.16\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.020907\talpha_max: 0.336628\tepsilon: 4.81\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.052071\talpha_max: 0.336628\tepsilon: 4.46\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.014840\talpha_max: 0.370291\tepsilon: 4.11\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.005969\talpha_max: 0.370291\tepsilon: 3.76\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.006356\talpha_max: 0.407320\tepsilon: 3.41\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.002219\talpha_max: 0.407320\tepsilon: 3.06\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.007358\talpha_max: 0.448052\tepsilon: 2.71\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.003534\talpha_max: 0.448052\tepsilon: 2.36\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.001230\talpha_max: 0.345000\tepsilon: 2.01\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.002022\talpha_max: 0.345000\tepsilon: 1.66\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.000634\talpha_max: 0.379500\tepsilon: 1.31\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.000741\talpha_max: 0.379500\tepsilon: 0.96\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.000618\talpha_max: 0.396577\tepsilon: 0.61\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.000507\talpha_max: 0.396577\tepsilon: 0.26\n",
      "Now is worker 8\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.662428\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 1.567945\talpha_max: 0.436235\tepsilon: 7.56\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.814420\talpha_max: 0.436235\tepsilon: 7.21\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 1.640818\talpha_max: 0.455866\tepsilon: 6.86\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.361563\talpha_max: 0.455866\tepsilon: 6.51\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.176512\talpha_max: 0.501452\tepsilon: 6.16\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.498319\talpha_max: 0.501452\tepsilon: 5.76\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.039443\talpha_max: 0.551597\tepsilon: 5.40\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.126918\talpha_max: 0.551597\tepsilon: 5.03\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.178799\talpha_max: 0.576419\tepsilon: 4.66\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.219240\talpha_max: 0.576419\tepsilon: 4.29\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.540462\talpha_max: 0.602358\tepsilon: 3.92\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.219858\talpha_max: 0.602358\tepsilon: 3.47\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.143531\talpha_max: 0.662594\tepsilon: 3.06\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.019659\talpha_max: 0.662594\tepsilon: 2.65\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 1.823709\talpha_max: 0.655968\tepsilon: 2.24\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.063518\talpha_max: 0.655968\tepsilon: 1.83\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.187877\talpha_max: 0.685487\tepsilon: 1.42\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.017174\talpha_max: 0.685487\tepsilon: 1.01\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.035796\talpha_max: 0.716334\tepsilon: 0.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.017642\talpha_max: 0.716334\tepsilon: 0.19\n",
      "Now is worker 9\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.532134\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.227284\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 3.182990\talpha_max: 0.478887\tepsilon: 7.27\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.482865\talpha_max: 0.478887\tepsilon: 6.93\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 1.703150\talpha_max: 0.447759\tepsilon: 6.60\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 1.538484\talpha_max: 0.447759\tepsilon: 6.27\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.668323\talpha_max: 0.492535\tepsilon: 5.89\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.713614\talpha_max: 0.492535\tepsilon: 5.54\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.411134\talpha_max: 0.460520\tepsilon: 5.19\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.147308\talpha_max: 0.460520\tepsilon: 4.84\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.581248\talpha_max: 0.506572\tepsilon: 4.49\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.167535\talpha_max: 0.506572\tepsilon: 4.14\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.261806\talpha_max: 0.557230\tepsilon: 3.75\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.581479\talpha_max: 0.557230\tepsilon: 3.38\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.092939\talpha_max: 0.612953\tepsilon: 3.02\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.010289\talpha_max: 0.612953\tepsilon: 2.59\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.011265\talpha_max: 0.606823\tepsilon: 2.20\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.029923\talpha_max: 0.606823\tepsilon: 1.82\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.056825\talpha_max: 0.667505\tepsilon: 1.43\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.001950\talpha_max: 0.667505\tepsilon: 1.04\n",
      "Train rounds: 2 [0/60000 (0%)]\tLoss: 0.627574\talpha_max: 0.734256\tepsilon: 0.65\n",
      "Train rounds: 2 [300/60000 (0%)]\tLoss: 0.060459\talpha_max: 0.734256\tepsilon: 0.26\n",
      "\n",
      "Test set: Average loss: 0.2923, Accuracy: 9363/10000 (94%)\tepsilon: -0.02\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.623298\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.359221\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.347479\talpha_max: 0.464215\tepsilon: 7.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.217787\talpha_max: 0.464215\tepsilon: 6.93\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.162768\talpha_max: 0.331914\tepsilon: 6.60\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.027084\talpha_max: 0.331914\tepsilon: 6.27\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.146853\talpha_max: 0.346850\tepsilon: 5.89\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.017863\talpha_max: 0.346850\tepsilon: 5.49\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.057571\talpha_max: 0.343381\tepsilon: 5.13\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.014854\talpha_max: 0.343381\tepsilon: 4.76\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.016343\talpha_max: 0.321062\tepsilon: 4.39\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.008100\talpha_max: 0.321062\tepsilon: 4.02\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.014195\talpha_max: 0.353168\tepsilon: 3.65\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.006685\talpha_max: 0.353168\tepsilon: 3.28\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.003319\talpha_max: 0.291363\tepsilon: 2.92\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.005978\talpha_max: 0.291363\tepsilon: 2.55\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.001628\talpha_max: 0.256400\tepsilon: 2.18\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.003176\talpha_max: 0.256400\tepsilon: 1.81\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.002136\talpha_max: 0.253836\tepsilon: 1.44\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.001453\talpha_max: 0.253836\tepsilon: 1.07\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.002971\talpha_max: 0.195454\tepsilon: 0.71\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.002437\talpha_max: 0.195454\tepsilon: 0.34\n",
      "Now is worker 1\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.727658\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.127988\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.425057\talpha_max: 0.093500\tepsilon: 7.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.106766\talpha_max: 0.093500\tepsilon: 6.93\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.288012\talpha_max: 0.077138\tepsilon: 6.60\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.061799\talpha_max: 0.077138\tepsilon: 6.27\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.261888\talpha_max: 0.076366\tepsilon: 5.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.072328\talpha_max: 0.076366\tepsilon: 5.56\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.232484\talpha_max: 0.084003\tepsilon: 5.21\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.041031\talpha_max: 0.084003\tepsilon: 4.86\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.235033\talpha_max: 0.092403\tepsilon: 4.51\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.021886\talpha_max: 0.092403\tepsilon: 4.16\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.193454\talpha_max: 0.091479\tepsilon: 3.75\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.022981\talpha_max: 0.091479\tepsilon: 3.39\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.198508\talpha_max: 0.095596\tepsilon: 2.97\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.030827\talpha_max: 0.095596\tepsilon: 2.58\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.127511\talpha_max: 0.105155\tepsilon: 2.13\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.019769\talpha_max: 0.105155\tepsilon: 1.72\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.068995\talpha_max: 0.109887\tepsilon: 1.31\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.014859\talpha_max: 0.109887\tepsilon: 0.90\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.084481\talpha_max: 0.102744\tepsilon: 0.38\n",
      "Now is worker 2\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.053928\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.084885\talpha_max: 0.099000\tepsilon: 7.51\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.010114\talpha_max: 0.099000\tepsilon: 7.14\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.019481\talpha_max: 0.103455\tepsilon: 6.77\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.022136\talpha_max: 0.103455\tepsilon: 6.41\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.033293\talpha_max: 0.102420\tepsilon: 6.04\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.012343\talpha_max: 0.102420\tepsilon: 5.67\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.011865\talpha_max: 0.112662\tepsilon: 5.23\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.012926\talpha_max: 0.112662\tepsilon: 4.76\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.006001\talpha_max: 0.123929\tepsilon: 4.33\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.005730\talpha_max: 0.123929\tepsilon: 3.89\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.011789\talpha_max: 0.115873\tepsilon: 3.46\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.006330\talpha_max: 0.115873\tepsilon: 3.02\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.005024\talpha_max: 0.121088\tepsilon: 2.54\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.005090\talpha_max: 0.121088\tepsilon: 2.07\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.003306\talpha_max: 0.133196\tepsilon: 1.61\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.005296\talpha_max: 0.133196\tepsilon: 1.15\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.002750\talpha_max: 0.124539\tepsilon: 0.64\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.002922\talpha_max: 0.124539\tepsilon: 0.15\n",
      "Now is worker 3\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.337968\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.388268\talpha_max: 0.095895\tepsilon: 7.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.133259\talpha_max: 0.095895\tepsilon: 7.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.205081\talpha_max: 0.105484\tepsilon: 6.93\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.137408\talpha_max: 0.105484\tepsilon: 6.56\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.107895\talpha_max: 0.110231\tepsilon: 6.21\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.054409\talpha_max: 0.110231\tepsilon: 5.86\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.066992\talpha_max: 0.121254\tepsilon: 5.51\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.050150\talpha_max: 0.121254\tepsilon: 5.16\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.049708\talpha_max: 0.106704\tepsilon: 4.81\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.031703\talpha_max: 0.106704\tepsilon: 4.46\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.021799\talpha_max: 0.111505\tepsilon: 4.11\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.025813\talpha_max: 0.111505\tepsilon: 3.76\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.032631\talpha_max: 0.110390\tepsilon: 3.36\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.011728\talpha_max: 0.110390\tepsilon: 3.00\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.013181\talpha_max: 0.121429\tepsilon: 2.57\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.007935\talpha_max: 0.121429\tepsilon: 2.15\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.005955\talpha_max: 0.126894\tepsilon: 1.74\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.009916\talpha_max: 0.126894\tepsilon: 1.33\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.006890\talpha_max: 0.139583\tepsilon: 0.80\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.008851\talpha_max: 0.139583\tepsilon: 0.33\n",
      "Now is worker 4\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.756566\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.212828\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.066142\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.145326\talpha_max: 0.110000\tepsilon: 6.93\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.040524\talpha_max: 0.108900\tepsilon: 6.60\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.055791\talpha_max: 0.108900\tepsilon: 6.27\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.031726\talpha_max: 0.119790\tepsilon: 5.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.024473\talpha_max: 0.119790\tepsilon: 5.52\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.036004\talpha_max: 0.131769\tepsilon: 5.10\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.022423\talpha_max: 0.131769\tepsilon: 4.71\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.030392\talpha_max: 0.144946\tepsilon: 4.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.010717\talpha_max: 0.144946\tepsilon: 3.86\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.011223\talpha_max: 0.119580\tepsilon: 3.45\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.011661\talpha_max: 0.119580\tepsilon: 3.04\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.009333\talpha_max: 0.131538\tepsilon: 2.63\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.004974\talpha_max: 0.131538\tepsilon: 2.21\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.006778\talpha_max: 0.144692\tepsilon: 1.80\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.004934\talpha_max: 0.144692\tepsilon: 1.35\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.007318\talpha_max: 0.151203\tepsilon: 0.92\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.003022\talpha_max: 0.151203\tepsilon: 0.42\n",
      "Now is worker 5\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.472854\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.439184\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.311237\talpha_max: 0.156427\tepsilon: 7.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.237471\talpha_max: 0.156427\tepsilon: 6.93\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.095777\talpha_max: 0.163467\tepsilon: 6.60\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.131762\talpha_max: 0.163467\tepsilon: 6.27\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.100059\talpha_max: 0.179813\tepsilon: 5.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.059430\talpha_max: 0.179813\tepsilon: 5.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.023340\talpha_max: 0.187905\tepsilon: 5.22\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.052589\talpha_max: 0.187905\tepsilon: 4.87\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.017699\talpha_max: 0.186026\tepsilon: 4.46\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.022432\talpha_max: 0.186026\tepsilon: 4.10\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.017695\talpha_max: 0.204629\tepsilon: 3.73\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.014213\talpha_max: 0.204629\tepsilon: 3.36\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.004906\talpha_max: 0.213837\tepsilon: 2.94\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.010059\talpha_max: 0.213837\tepsilon: 2.55\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.002134\talpha_max: 0.188176\tepsilon: 2.16\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.005582\talpha_max: 0.188176\tepsilon: 1.77\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.003748\talpha_max: 0.186295\tepsilon: 1.38\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.005352\talpha_max: 0.186295\tepsilon: 0.99\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.001745\talpha_max: 0.204924\tepsilon: 0.61\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.010177\talpha_max: 0.204924\tepsilon: 0.22\n",
      "Now is worker 6\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.197833\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.052202\talpha_max: 0.100000\tepsilon: 7.56\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.113363\talpha_max: 0.110000\tepsilon: 7.21\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.010693\talpha_max: 0.110000\tepsilon: 6.86\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.101816\talpha_max: 0.096800\tepsilon: 6.51\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.014407\talpha_max: 0.096800\tepsilon: 6.11\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.069878\talpha_max: 0.101156\tepsilon: 5.74\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.030371\talpha_max: 0.101156\tepsilon: 5.37\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.070010\talpha_max: 0.111272\tepsilon: 5.00\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.012098\talpha_max: 0.111272\tepsilon: 4.63\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.042759\talpha_max: 0.116279\tepsilon: 4.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.010528\talpha_max: 0.116279\tepsilon: 3.90\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.026688\talpha_max: 0.127907\tepsilon: 3.53\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.010563\talpha_max: 0.127907\tepsilon: 3.12\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.028265\talpha_max: 0.126628\tepsilon: 2.74\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.007542\talpha_max: 0.126628\tepsilon: 2.35\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.011026\talpha_max: 0.139290\tepsilon: 1.96\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.006279\talpha_max: 0.139290\tepsilon: 1.57\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.016986\talpha_max: 0.153219\tepsilon: 1.18\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.004262\talpha_max: 0.153219\tepsilon: 0.79\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.008723\talpha_max: 0.151687\tepsilon: 0.40\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.001756\talpha_max: 0.151687\tepsilon: 0.02\n",
      "Now is worker 7\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.304646\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.068569\talpha_max: 0.158513\tepsilon: 7.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.110850\talpha_max: 0.158513\tepsilon: 7.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.112087\talpha_max: 0.156928\tepsilon: 6.93\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.117532\talpha_max: 0.156928\tepsilon: 6.60\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.083577\talpha_max: 0.138097\tepsilon: 6.27\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.022893\talpha_max: 0.138097\tepsilon: 5.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.023072\talpha_max: 0.144311\tepsilon: 5.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.009995\talpha_max: 0.144311\tepsilon: 5.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.012664\talpha_max: 0.158742\tepsilon: 4.89\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.009109\talpha_max: 0.158742\tepsilon: 4.54\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.009031\talpha_max: 0.139693\tepsilon: 4.19\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.009785\talpha_max: 0.139693\tepsilon: 3.84\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.010400\talpha_max: 0.153662\tepsilon: 3.45\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.006604\talpha_max: 0.153662\tepsilon: 3.08\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.006558\talpha_max: 0.135223\tepsilon: 2.67\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.005624\talpha_max: 0.135223\tepsilon: 2.28\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.004941\talpha_max: 0.133871\tepsilon: 1.89\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.004471\talpha_max: 0.133871\tepsilon: 1.45\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.013666\talpha_max: 0.147258\tepsilon: 1.00\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.002759\talpha_max: 0.147258\tepsilon: 0.51\n",
      "Now is worker 8\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.122125\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.250403\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.105081\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.107108\talpha_max: 0.110000\tepsilon: 6.93\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.095496\talpha_max: 0.102850\tepsilon: 6.60\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.064753\talpha_max: 0.102850\tepsilon: 6.27\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.087130\talpha_max: 0.113135\tepsilon: 5.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.057876\talpha_max: 0.113135\tepsilon: 5.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.087560\talpha_max: 0.124449\tepsilon: 5.23\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.055018\talpha_max: 0.124449\tepsilon: 4.88\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.018647\talpha_max: 0.130049\tepsilon: 4.53\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.044253\talpha_max: 0.130049\tepsilon: 4.14\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.007282\talpha_max: 0.143054\tepsilon: 3.77\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.027921\talpha_max: 0.143054\tepsilon: 3.40\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.008683\talpha_max: 0.149491\tepsilon: 3.03\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.027271\talpha_max: 0.149491\tepsilon: 2.67\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.004696\talpha_max: 0.164440\tepsilon: 2.24\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.024079\talpha_max: 0.164440\tepsilon: 1.85\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.007425\talpha_max: 0.180884\tepsilon: 1.47\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.011446\talpha_max: 0.180884\tepsilon: 1.08\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.011536\talpha_max: 0.189024\tepsilon: 0.69\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.013182\talpha_max: 0.189024\tepsilon: 0.30\n",
      "Now is worker 9\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.373386\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.370378\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.165447\talpha_max: 0.093500\tepsilon: 7.27\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.261431\talpha_max: 0.093500\tepsilon: 6.83\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.163165\talpha_max: 0.102850\tepsilon: 6.47\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.247431\talpha_max: 0.102850\tepsilon: 6.10\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.088818\talpha_max: 0.113135\tepsilon: 5.73\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.117225\talpha_max: 0.113135\tepsilon: 5.36\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.071493\talpha_max: 0.118226\tepsilon: 4.99\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.110396\talpha_max: 0.118226\tepsilon: 4.62\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.067482\talpha_max: 0.123546\tepsilon: 4.26\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.100177\talpha_max: 0.123546\tepsilon: 3.89\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.056166\talpha_max: 0.135901\tepsilon: 3.52\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.093803\talpha_max: 0.135901\tepsilon: 3.15\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.018742\talpha_max: 0.149491\tepsilon: 2.78\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.075274\talpha_max: 0.149491\tepsilon: 2.41\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.016069\talpha_max: 0.156218\tepsilon: 2.00\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.078031\talpha_max: 0.156218\tepsilon: 1.61\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.008547\talpha_max: 0.146064\tepsilon: 1.22\n",
      "Train rounds: 3 [300/60000 (0%)]\tLoss: 0.027147\talpha_max: 0.146064\tepsilon: 0.78\n",
      "Train rounds: 3 [0/60000 (0%)]\tLoss: 0.010205\talpha_max: 0.160670\tepsilon: 0.37\n",
      "\n",
      "Test set: Average loss: 0.2387, Accuracy: 9477/10000 (95%)\tepsilon: -0.00\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.161566\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.095738\talpha_max: 0.176737\tepsilon: 7.60\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.108835\talpha_max: 0.176737\tepsilon: 7.27\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.031066\talpha_max: 0.174970\tepsilon: 6.93\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.042623\talpha_max: 0.174970\tepsilon: 6.60\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.009830\talpha_max: 0.192467\tepsilon: 6.27\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.016178\talpha_max: 0.192467\tepsilon: 5.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.008615\talpha_max: 0.190542\tepsilon: 5.60\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.011024\talpha_max: 0.190542\tepsilon: 5.27\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.007718\talpha_max: 0.209596\tepsilon: 4.93\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.011389\talpha_max: 0.209596\tepsilon: 4.56\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.010472\talpha_max: 0.230556\tepsilon: 4.21\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.006897\talpha_max: 0.230556\tepsilon: 3.86\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.007852\talpha_max: 0.240931\tepsilon: 3.51\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.004597\talpha_max: 0.240931\tepsilon: 3.16\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.029616\talpha_max: 0.265024\tepsilon: 2.81\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.006624\talpha_max: 0.265024\tepsilon: 2.46\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.079924\talpha_max: 0.247798\tepsilon: 2.11\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.004411\talpha_max: 0.247798\tepsilon: 1.76\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.006598\talpha_max: 0.272577\tepsilon: 1.37\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.002202\talpha_max: 0.272577\tepsilon: 1.00\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.002798\talpha_max: 0.254860\tepsilon: 0.63\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.003315\talpha_max: 0.254860\tepsilon: 0.26\n",
      "Now is worker 1\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.205572\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.307982\talpha_max: 0.266329\tepsilon: 7.60\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.122710\talpha_max: 0.266329\tepsilon: 7.27\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.239707\talpha_max: 0.278313\tepsilon: 6.93\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.017257\talpha_max: 0.278313\tepsilon: 6.60\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.051078\talpha_max: 0.244916\tepsilon: 6.27\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.016019\talpha_max: 0.244916\tepsilon: 5.84\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.072504\talpha_max: 0.242467\tepsilon: 5.48\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.018827\talpha_max: 0.242467\tepsilon: 5.06\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.010304\talpha_max: 0.226706\tepsilon: 4.67\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.005734\talpha_max: 0.226706\tepsilon: 4.28\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.010965\talpha_max: 0.211970\tepsilon: 3.89\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.006124\talpha_max: 0.211970\tepsilon: 3.50\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.006950\talpha_max: 0.233167\tepsilon: 3.12\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.003852\talpha_max: 0.233167\tepsilon: 2.73\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.003204\talpha_max: 0.205187\tepsilon: 2.34\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.003851\talpha_max: 0.205187\tepsilon: 1.95\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.003418\talpha_max: 0.203135\tepsilon: 1.56\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.002641\talpha_max: 0.203135\tepsilon: 1.17\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.002310\talpha_max: 0.178759\tepsilon: 0.69\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.002547\talpha_max: 0.178759\tepsilon: 0.25\n",
      "Now is worker 2\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.224347\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.471362\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.213924\talpha_max: 0.162224\tepsilon: 7.23\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.146979\talpha_max: 0.162224\tepsilon: 6.88\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.105450\talpha_max: 0.169524\tepsilon: 6.49\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.045250\talpha_max: 0.169524\tepsilon: 6.12\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.030479\talpha_max: 0.177153\tepsilon: 5.75\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.038714\talpha_max: 0.177153\tepsilon: 5.38\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.053765\talpha_max: 0.194868\tepsilon: 5.02\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.014637\talpha_max: 0.194868\tepsilon: 4.65\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.013879\talpha_max: 0.214355\tepsilon: 4.23\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.013090\talpha_max: 0.214355\tepsilon: 3.84\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.006857\talpha_max: 0.235790\tepsilon: 3.46\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.008665\talpha_max: 0.235790\tepsilon: 3.02\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.003713\talpha_max: 0.259369\tepsilon: 2.51\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.004751\talpha_max: 0.259369\tepsilon: 2.05\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.004204\talpha_max: 0.271041\tepsilon: 1.58\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.005671\talpha_max: 0.271041\tepsilon: 1.12\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.001032\talpha_max: 0.298145\tepsilon: 0.66\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.003387\talpha_max: 0.298145\tepsilon: 0.20\n",
      "Now is worker 3\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.324681\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.045525\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.105692\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.027656\talpha_max: 0.110000\tepsilon: 6.93\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.083522\talpha_max: 0.108900\tepsilon: 6.60\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.035958\talpha_max: 0.108900\tepsilon: 6.27\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.050992\talpha_max: 0.089843\tepsilon: 5.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.024058\talpha_max: 0.089843\tepsilon: 5.60\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.039133\talpha_max: 0.098827\tepsilon: 5.27\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.023548\talpha_max: 0.098827\tepsilon: 4.93\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.015556\talpha_max: 0.103274\tepsilon: 4.55\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.018472\talpha_max: 0.103274\tepsilon: 4.20\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.009585\talpha_max: 0.096561\tepsilon: 3.85\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.009351\talpha_max: 0.096561\tepsilon: 3.35\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.013876\talpha_max: 0.106217\tepsilon: 2.84\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.007496\talpha_max: 0.106217\tepsilon: 2.38\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.016518\talpha_max: 0.099313\tepsilon: 1.86\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.005714\talpha_max: 0.099313\tepsilon: 1.37\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.006666\talpha_max: 0.081933\tepsilon: 0.88\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.004610\talpha_max: 0.081933\tepsilon: 0.39\n",
      "Now is worker 4\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.905736\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.254346\talpha_max: 0.090127\tepsilon: 7.56\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.639475\talpha_max: 0.090127\tepsilon: 7.15\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.174020\talpha_max: 0.099139\tepsilon: 6.79\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.185362\talpha_max: 0.099139\tepsilon: 6.42\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.077330\talpha_max: 0.109053\tepsilon: 6.00\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.142295\talpha_max: 0.109053\tepsilon: 5.61\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.041833\talpha_max: 0.107963\tepsilon: 5.22\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.109942\talpha_max: 0.107963\tepsilon: 4.83\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.008805\talpha_max: 0.100945\tepsilon: 4.44\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.084297\talpha_max: 0.100945\tepsilon: 4.05\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.015162\talpha_max: 0.099936\tepsilon: 3.66\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.053612\talpha_max: 0.099936\tepsilon: 3.28\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.006916\talpha_max: 0.104433\tepsilon: 2.85\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.062740\talpha_max: 0.104433\tepsilon: 2.44\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.004459\talpha_max: 0.114876\tepsilon: 2.03\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.035160\talpha_max: 0.114876\tepsilon: 1.62\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.013622\talpha_max: 0.126364\tepsilon: 1.21\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.021522\talpha_max: 0.126364\tepsilon: 0.68\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.004985\talpha_max: 0.139000\tepsilon: 0.16\n",
      "Now is worker 5\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.065463\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.194568\talpha_max: 0.122320\tepsilon: 7.60\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.079755\talpha_max: 0.122320\tepsilon: 7.22\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.134871\talpha_max: 0.134552\tepsilon: 6.87\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.022642\talpha_max: 0.134552\tepsilon: 6.48\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.073400\talpha_max: 0.148007\tepsilon: 6.07\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.027489\talpha_max: 0.148007\tepsilon: 5.68\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.054394\talpha_max: 0.162808\tepsilon: 5.30\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.007123\talpha_max: 0.162808\tepsilon: 4.91\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.026269\talpha_max: 0.179089\tepsilon: 4.48\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.020601\talpha_max: 0.179089\tepsilon: 4.06\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.007041\talpha_max: 0.196998\tepsilon: 3.65\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.002440\talpha_max: 0.196998\tepsilon: 3.24\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.004212\talpha_max: 0.205863\tepsilon: 2.75\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.001652\talpha_max: 0.205863\tepsilon: 2.29\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.001875\talpha_max: 0.226449\tepsilon: 1.83\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.001298\talpha_max: 0.226449\tepsilon: 1.32\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.000906\talpha_max: 0.211730\tepsilon: 0.79\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.000760\talpha_max: 0.211730\tepsilon: 0.20\n",
      "Now is worker 6\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.082402\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.048531\talpha_max: 0.221258\tepsilon: 7.60\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.044833\talpha_max: 0.221258\tepsilon: 7.27\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.022119\talpha_max: 0.231214\tepsilon: 6.93\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.047175\talpha_max: 0.231214\tepsilon: 6.60\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.031943\talpha_max: 0.254336\tepsilon: 6.27\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.007671\talpha_max: 0.254336\tepsilon: 5.89\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.012669\talpha_max: 0.279769\tepsilon: 5.54\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.004635\talpha_max: 0.279769\tepsilon: 5.14\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.001836\talpha_max: 0.307746\tepsilon: 4.77\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.006491\talpha_max: 0.307746\tepsilon: 4.40\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.003284\talpha_max: 0.321595\tepsilon: 3.98\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.006203\talpha_max: 0.321595\tepsilon: 3.59\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.002160\talpha_max: 0.353754\tepsilon: 3.20\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.000879\talpha_max: 0.353754\tepsilon: 2.76\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.000564\talpha_max: 0.291847\tepsilon: 2.35\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.002207\talpha_max: 0.291847\tepsilon: 1.94\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.000266\talpha_max: 0.304980\tepsilon: 1.53\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.000673\talpha_max: 0.304980\tepsilon: 1.08\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.000848\talpha_max: 0.318704\tepsilon: 0.64\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.000932\talpha_max: 0.318704\tepsilon: 0.21\n",
      "Now is worker 7\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.242337\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.032451\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.159942\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.020086\talpha_max: 0.110000\tepsilon: 6.85\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.106038\talpha_max: 0.121000\tepsilon: 6.48\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.011929\talpha_max: 0.121000\tepsilon: 6.12\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.045895\talpha_max: 0.126445\tepsilon: 5.75\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.006979\talpha_max: 0.126445\tepsilon: 5.38\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.037070\talpha_max: 0.097363\tepsilon: 5.01\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.007935\talpha_max: 0.097363\tepsilon: 4.64\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.044139\talpha_max: 0.091034\tepsilon: 4.27\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.003201\talpha_max: 0.091034\tepsilon: 3.91\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.046469\talpha_max: 0.095131\tepsilon: 3.54\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.008342\talpha_max: 0.095131\tepsilon: 3.17\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.041150\talpha_max: 0.083715\tepsilon: 2.80\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.003589\talpha_max: 0.083715\tepsilon: 2.43\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.034605\talpha_max: 0.087482\tepsilon: 2.02\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.001268\talpha_max: 0.087482\tepsilon: 1.63\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.029591\talpha_max: 0.096230\tepsilon: 1.24\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.002943\talpha_max: 0.096230\tepsilon: 0.86\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.027124\talpha_max: 0.105853\tepsilon: 0.42\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.001945\talpha_max: 0.105853\tepsilon: 0.01\n",
      "Now is worker 8\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.225656\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.106020\talpha_max: 0.110617\tepsilon: 7.56\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.097069\talpha_max: 0.110617\tepsilon: 7.21\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.032161\talpha_max: 0.121678\tepsilon: 6.86\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.109147\talpha_max: 0.121678\tepsilon: 6.51\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.014339\talpha_max: 0.120462\tepsilon: 6.16\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.057264\talpha_max: 0.120462\tepsilon: 5.78\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.010692\talpha_max: 0.106006\tepsilon: 5.37\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.007153\talpha_max: 0.106006\tepsilon: 4.98\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.011824\talpha_max: 0.110777\tepsilon: 4.59\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.005422\talpha_max: 0.110777\tepsilon: 4.20\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.020037\talpha_max: 0.109669\tepsilon: 3.81\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.007134\talpha_max: 0.109669\tepsilon: 3.42\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.005341\talpha_max: 0.096509\tepsilon: 2.99\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.003242\talpha_max: 0.096509\tepsilon: 2.58\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.006275\talpha_max: 0.069004\tepsilon: 2.17\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.008133\talpha_max: 0.069004\tepsilon: 1.62\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.002942\talpha_max: 0.075904\tepsilon: 1.13\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.001557\talpha_max: 0.075904\tepsilon: 0.63\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.002819\talpha_max: 0.083494\tepsilon: 0.14\n",
      "Now is worker 9\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.125432\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.790851\talpha_max: 0.100000\tepsilon: 7.55\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.051187\talpha_max: 0.104500\tepsilon: 7.20\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.715405\talpha_max: 0.104500\tepsilon: 6.85\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.015323\talpha_max: 0.091960\tepsilon: 6.50\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.595350\talpha_max: 0.091960\tepsilon: 6.10\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.033129\talpha_max: 0.096098\tepsilon: 5.73\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.290936\talpha_max: 0.096098\tepsilon: 5.36\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.014789\talpha_max: 0.089852\tepsilon: 4.95\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.167702\talpha_max: 0.089852\tepsilon: 4.57\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.008651\talpha_max: 0.098837\tepsilon: 4.18\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.056106\talpha_max: 0.098837\tepsilon: 3.79\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.008027\talpha_max: 0.086977\tepsilon: 3.40\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.036397\talpha_max: 0.086977\tepsilon: 3.01\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.004620\talpha_max: 0.090891\tepsilon: 2.57\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.024921\talpha_max: 0.090891\tepsilon: 2.16\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.006956\talpha_max: 0.094981\tepsilon: 1.75\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.033101\talpha_max: 0.094981\tepsilon: 1.34\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.004618\talpha_max: 0.094031\tepsilon: 0.93\n",
      "Train rounds: 4 [300/60000 (0%)]\tLoss: 0.014691\talpha_max: 0.094031\tepsilon: 0.48\n",
      "Train rounds: 4 [0/60000 (0%)]\tLoss: 0.005201\talpha_max: 0.093090\tepsilon: 0.04\n",
      "\n",
      "Test set: Average loss: 0.1911, Accuracy: 9557/10000 (96%)\tepsilon: -0.01\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.273385\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.190911\talpha_max: 0.100000\tepsilon: 7.56\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.104989\talpha_max: 0.102400\tepsilon: 7.21\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.054818\talpha_max: 0.102400\tepsilon: 6.86\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.062351\talpha_max: 0.112639\tepsilon: 6.51\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.026053\talpha_max: 0.112639\tepsilon: 6.16\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.035302\talpha_max: 0.123903\tepsilon: 5.81\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.020262\talpha_max: 0.123903\tepsilon: 5.46\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.024898\talpha_max: 0.136294\tepsilon: 5.11\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.021571\talpha_max: 0.136294\tepsilon: 4.71\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.018394\talpha_max: 0.142427\tepsilon: 4.34\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.009843\talpha_max: 0.142427\tepsilon: 3.97\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.026603\talpha_max: 0.141003\tepsilon: 3.61\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.014029\talpha_max: 0.141003\tepsilon: 3.24\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.008755\talpha_max: 0.131838\tepsilon: 2.87\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.007554\talpha_max: 0.131838\tepsilon: 2.50\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.004170\talpha_max: 0.137770\tepsilon: 2.13\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005106\talpha_max: 0.137770\tepsilon: 1.76\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.004995\talpha_max: 0.151547\tepsilon: 1.40\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005272\talpha_max: 0.151547\tepsilon: 1.03\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.009525\talpha_max: 0.158367\tepsilon: 0.66\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.003221\talpha_max: 0.158367\tepsilon: 0.29\n",
      "Now is worker 1\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.009346\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.066264\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.067961\talpha_max: 0.136532\tepsilon: 7.27\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.075067\talpha_max: 0.136532\tepsilon: 6.93\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.006407\talpha_max: 0.142676\tepsilon: 6.60\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.028319\talpha_max: 0.142676\tepsilon: 6.27\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.008700\talpha_max: 0.156944\tepsilon: 5.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.019796\talpha_max: 0.156944\tepsilon: 5.60\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.005222\talpha_max: 0.164006\tepsilon: 5.27\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.012021\talpha_max: 0.164006\tepsilon: 4.89\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.001180\talpha_max: 0.180407\tepsilon: 4.54\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.013565\talpha_max: 0.180407\tepsilon: 4.19\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002667\talpha_max: 0.198447\tepsilon: 3.84\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.004099\talpha_max: 0.198447\tepsilon: 3.49\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.001035\talpha_max: 0.196463\tepsilon: 3.14\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005802\talpha_max: 0.196463\tepsilon: 2.79\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.000741\talpha_max: 0.216109\tepsilon: 2.39\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.004243\talpha_max: 0.216109\tepsilon: 2.02\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.000587\talpha_max: 0.225834\tepsilon: 1.65\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.003245\talpha_max: 0.225834\tepsilon: 1.29\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.000516\talpha_max: 0.248417\tepsilon: 0.92\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.000920\talpha_max: 0.248417\tepsilon: 0.55\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.000601\talpha_max: 0.259596\tepsilon: 0.18\n",
      "Now is worker 2\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.317255\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.377062\talpha_max: 0.199889\tepsilon: 7.60\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.236152\talpha_max: 0.199889\tepsilon: 7.27\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.014871\talpha_max: 0.219878\tepsilon: 6.93\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.170951\talpha_max: 0.219878\tepsilon: 6.60\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.015139\talpha_max: 0.181399\tepsilon: 6.27\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.017779\talpha_max: 0.181399\tepsilon: 5.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.009997\talpha_max: 0.189562\tepsilon: 5.60\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.030542\talpha_max: 0.189562\tepsilon: 5.22\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.013619\talpha_max: 0.177241\tepsilon: 4.87\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.005234\talpha_max: 0.177241\tepsilon: 4.47\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005716\talpha_max: 0.175468\tepsilon: 4.10\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.006089\talpha_max: 0.175468\tepsilon: 3.73\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.003866\talpha_max: 0.173714\tepsilon: 3.36\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.003173\talpha_max: 0.173714\tepsilon: 2.94\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.002592\talpha_max: 0.171977\tepsilon: 2.55\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.004246\talpha_max: 0.171977\tepsilon: 2.16\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.002059\talpha_max: 0.189174\tepsilon: 1.78\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002934\talpha_max: 0.189174\tepsilon: 1.39\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.002762\talpha_max: 0.187282\tepsilon: 1.00\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002364\talpha_max: 0.187282\tepsilon: 0.56\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.003217\talpha_max: 0.164809\tepsilon: 0.15\n",
      "Now is worker 3\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.393289\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005565\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.088098\talpha_max: 0.181289\tepsilon: 7.27\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.018218\talpha_max: 0.181289\tepsilon: 6.93\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.078236\talpha_max: 0.199418\tepsilon: 6.52\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.008211\talpha_max: 0.199418\tepsilon: 6.15\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.044523\talpha_max: 0.219360\tepsilon: 5.78\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.003723\talpha_max: 0.219360\tepsilon: 5.41\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.021996\talpha_max: 0.193037\tepsilon: 5.05\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005461\talpha_max: 0.193037\tepsilon: 4.68\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.020650\talpha_max: 0.212341\tepsilon: 4.31\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.002795\talpha_max: 0.212341\tepsilon: 3.90\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.020544\talpha_max: 0.233575\tepsilon: 3.51\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.001499\talpha_max: 0.233575\tepsilon: 3.12\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.011727\talpha_max: 0.231239\tepsilon: 2.73\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.001527\talpha_max: 0.231239\tepsilon: 2.34\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.007055\talpha_max: 0.241645\tepsilon: 1.91\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.000642\talpha_max: 0.241645\tepsilon: 1.44\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.006692\talpha_max: 0.212647\tepsilon: 1.01\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.000494\talpha_max: 0.212647\tepsilon: 0.57\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.003643\talpha_max: 0.233912\tepsilon: 0.14\n",
      "Now is worker 4\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.166199\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.098601\talpha_max: 0.180112\tepsilon: 7.51\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.048611\talpha_max: 0.180112\tepsilon: 7.14\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.088178\talpha_max: 0.198124\tepsilon: 6.78\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.106470\talpha_max: 0.198124\tepsilon: 6.41\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.040025\talpha_max: 0.217936\tepsilon: 6.04\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.041814\talpha_max: 0.217936\tepsilon: 5.63\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.034076\talpha_max: 0.191784\tepsilon: 5.24\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.034728\talpha_max: 0.191784\tepsilon: 4.74\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.035835\talpha_max: 0.168770\tepsilon: 4.31\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.011062\talpha_max: 0.168770\tepsilon: 3.87\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.009432\talpha_max: 0.157800\tepsilon: 3.44\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.006374\talpha_max: 0.157800\tepsilon: 3.00\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.008466\talpha_max: 0.173579\tepsilon: 2.53\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.007866\talpha_max: 0.173579\tepsilon: 2.01\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.006246\talpha_max: 0.190937\tepsilon: 1.46\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.005122\talpha_max: 0.190937\tepsilon: 0.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005513\talpha_max: 0.189028\tepsilon: 0.41\n",
      "Now is worker 5\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.026478\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.135949\talpha_max: 0.100000\tepsilon: 7.56\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.009430\talpha_max: 0.110000\tepsilon: 7.21\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.078328\talpha_max: 0.110000\tepsilon: 6.86\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.016524\talpha_max: 0.108900\tepsilon: 6.51\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.049830\talpha_max: 0.108900\tepsilon: 6.16\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.006285\talpha_max: 0.119790\tepsilon: 5.81\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.043905\talpha_max: 0.119790\tepsilon: 5.46\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.013473\talpha_max: 0.125181\tepsilon: 5.11\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.015841\talpha_max: 0.125181\tepsilon: 4.76\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.004601\talpha_max: 0.130814\tepsilon: 4.41\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.009999\talpha_max: 0.130814\tepsilon: 4.06\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002912\talpha_max: 0.143895\tepsilon: 3.71\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.012022\talpha_max: 0.143895\tepsilon: 3.36\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.010183\talpha_max: 0.158285\tepsilon: 2.95\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005146\talpha_max: 0.158285\tepsilon: 2.53\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002523\talpha_max: 0.130585\tepsilon: 2.14\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.003400\talpha_max: 0.130585\tepsilon: 1.76\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.003765\talpha_max: 0.114915\tepsilon: 1.37\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.004065\talpha_max: 0.114915\tepsilon: 0.93\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.001619\talpha_max: 0.126406\tepsilon: 0.41\n",
      "Now is worker 6\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.071819\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.462926\talpha_max: 0.125142\tepsilon: 7.60\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.085377\talpha_max: 0.125142\tepsilon: 7.27\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.229466\talpha_max: 0.130773\tepsilon: 6.93\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.026767\talpha_max: 0.130773\tepsilon: 6.60\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.139734\talpha_max: 0.115081\tepsilon: 6.27\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.016133\talpha_max: 0.115081\tepsilon: 5.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.112666\talpha_max: 0.113930\tepsilon: 5.55\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.006191\talpha_max: 0.113930\tepsilon: 5.15\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.129931\talpha_max: 0.125323\tepsilon: 4.79\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.008692\talpha_max: 0.125323\tepsilon: 4.42\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.046557\talpha_max: 0.130962\tepsilon: 4.05\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.003920\talpha_max: 0.130962\tepsilon: 3.68\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.040020\talpha_max: 0.144058\tepsilon: 3.31\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.006586\talpha_max: 0.144058\tepsilon: 2.94\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.036923\talpha_max: 0.158464\tepsilon: 2.53\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.001704\talpha_max: 0.158464\tepsilon: 2.15\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.010800\talpha_max: 0.174311\tepsilon: 1.76\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.004261\talpha_max: 0.174311\tepsilon: 1.37\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.035921\talpha_max: 0.191742\tepsilon: 0.98\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002200\talpha_max: 0.191742\tepsilon: 0.55\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.003733\talpha_max: 0.210916\tepsilon: 0.13\n",
      "Now is worker 7\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.236696\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.412962\talpha_max: 0.220407\tepsilon: 7.60\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.130232\talpha_max: 0.220407\tepsilon: 7.23\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.133295\talpha_max: 0.242448\tepsilon: 6.83\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.048111\talpha_max: 0.242448\tepsilon: 6.46\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.024558\talpha_max: 0.266693\tepsilon: 6.02\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.032232\talpha_max: 0.266693\tepsilon: 5.60\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.006451\talpha_max: 0.249358\tepsilon: 5.19\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.017082\talpha_max: 0.249358\tepsilon: 4.78\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005907\talpha_max: 0.233149\tepsilon: 4.33\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.006291\talpha_max: 0.233149\tepsilon: 3.89\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.005612\talpha_max: 0.256464\tepsilon: 3.46\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.007124\talpha_max: 0.256464\tepsilon: 3.02\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.002851\talpha_max: 0.268005\tepsilon: 2.59\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.001880\talpha_max: 0.268005\tepsilon: 2.11\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.002012\talpha_max: 0.294806\tepsilon: 1.65\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.003167\talpha_max: 0.294806\tepsilon: 1.15\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.001565\talpha_max: 0.324286\tepsilon: 0.65\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002197\talpha_max: 0.324286\tepsilon: 0.16\n",
      "Now is worker 8\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.040802\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.622339\talpha_max: 0.321044\tepsilon: 7.60\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.061170\talpha_max: 0.321044\tepsilon: 7.23\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.036623\talpha_max: 0.317833\tepsilon: 6.83\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.059973\talpha_max: 0.317833\tepsilon: 6.46\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.007356\talpha_max: 0.349616\tepsilon: 6.09\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.007083\talpha_max: 0.349616\tepsilon: 5.72\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.011065\talpha_max: 0.346120\tepsilon: 5.35\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002574\talpha_max: 0.346120\tepsilon: 4.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.002246\talpha_max: 0.304586\tepsilon: 4.50\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002284\talpha_max: 0.304586\tepsilon: 4.09\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.002893\talpha_max: 0.301540\tepsilon: 3.68\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002574\talpha_max: 0.301540\tepsilon: 3.23\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.001520\talpha_max: 0.331694\tepsilon: 2.76\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.000825\talpha_max: 0.331694\tepsilon: 2.24\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.001036\talpha_max: 0.346620\tepsilon: 1.75\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.000813\talpha_max: 0.346620\tepsilon: 1.20\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.001485\talpha_max: 0.381282\tepsilon: 0.68\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.000642\talpha_max: 0.381282\tepsilon: 0.15\n",
      "Now is worker 9\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.266913\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.506768\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.196527\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.213963\talpha_max: 0.110000\tepsilon: 6.90\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.027683\talpha_max: 0.114950\tepsilon: 6.55\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.041794\talpha_max: 0.114950\tepsilon: 6.14\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.016462\talpha_max: 0.120123\tepsilon: 5.78\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.012750\talpha_max: 0.120123\tepsilon: 5.41\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.006848\talpha_max: 0.118922\tepsilon: 5.04\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.013787\talpha_max: 0.118922\tepsilon: 4.63\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.005448\talpha_max: 0.104651\tepsilon: 4.24\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.006869\talpha_max: 0.104651\tepsilon: 3.80\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.007843\talpha_max: 0.109360\tepsilon: 3.39\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.004762\talpha_max: 0.109360\tepsilon: 2.98\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.004673\talpha_max: 0.114281\tepsilon: 2.57\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.004221\talpha_max: 0.114281\tepsilon: 2.16\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002123\talpha_max: 0.113139\tepsilon: 1.75\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.007373\talpha_max: 0.113139\tepsilon: 1.34\n",
      "Train rounds: 5 [0/60000 (0%)]\tLoss: 0.002928\talpha_max: 0.118230\tepsilon: 0.88\n",
      "Train rounds: 5 [300/60000 (0%)]\tLoss: 0.004356\talpha_max: 0.118230\tepsilon: 0.45\n",
      "\n",
      "Test set: Average loss: 0.1732, Accuracy: 9606/10000 (96%)\tepsilon: -0.02\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.192335\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.059227\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.058750\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.073989\talpha_max: 0.110000\tepsilon: 6.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.033232\talpha_max: 0.108900\tepsilon: 6.60\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.082431\talpha_max: 0.108900\tepsilon: 6.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.039741\talpha_max: 0.119790\tepsilon: 5.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.077437\talpha_max: 0.119790\tepsilon: 5.55\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.054807\talpha_max: 0.118592\tepsilon: 5.20\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.018887\talpha_max: 0.118592\tepsilon: 4.85\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.028424\talpha_max: 0.130451\tepsilon: 4.50\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.017090\talpha_max: 0.130451\tepsilon: 4.15\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.006880\talpha_max: 0.143496\tepsilon: 3.80\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.009670\talpha_max: 0.143496\tepsilon: 3.45\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.019063\talpha_max: 0.157846\tepsilon: 3.10\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.014373\talpha_max: 0.157846\tepsilon: 2.75\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.014588\talpha_max: 0.173631\tepsilon: 2.35\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.008376\talpha_max: 0.173631\tepsilon: 1.98\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.012988\talpha_max: 0.190994\tepsilon: 1.56\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.003745\talpha_max: 0.190994\tepsilon: 1.13\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004861\talpha_max: 0.199588\tepsilon: 0.72\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002463\talpha_max: 0.199588\tepsilon: 0.31\n",
      "Now is worker 1\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.030271\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.184348\talpha_max: 0.219547\tepsilon: 7.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.027787\talpha_max: 0.219547\tepsilon: 7.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.079825\talpha_max: 0.181127\tepsilon: 6.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.017880\talpha_max: 0.181127\tepsilon: 6.60\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.029236\talpha_max: 0.189277\tepsilon: 6.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.020312\talpha_max: 0.189277\tepsilon: 5.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.184241\talpha_max: 0.208205\tepsilon: 5.56\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.007674\talpha_max: 0.208205\tepsilon: 5.17\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.007566\talpha_max: 0.217574\tepsilon: 4.80\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.009078\talpha_max: 0.217574\tepsilon: 4.43\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002210\talpha_max: 0.239332\tepsilon: 4.01\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.005113\talpha_max: 0.239332\tepsilon: 3.62\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002039\talpha_max: 0.250102\tepsilon: 3.19\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004281\talpha_max: 0.250102\tepsilon: 2.78\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.000624\talpha_max: 0.275112\tepsilon: 2.37\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002254\talpha_max: 0.275112\tepsilon: 1.96\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002345\talpha_max: 0.287492\tepsilon: 1.55\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002330\talpha_max: 0.287492\tepsilon: 1.09\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.000855\talpha_max: 0.268805\tepsilon: 0.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003185\talpha_max: 0.268805\tepsilon: 0.14\n",
      "Now is worker 2\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.024066\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.191406\talpha_max: 0.100000\tepsilon: 7.56\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.093162\talpha_max: 0.292728\tepsilon: 7.21\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.055038\talpha_max: 0.292728\tepsilon: 6.86\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.005555\talpha_max: 0.257601\tepsilon: 6.51\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.040795\talpha_max: 0.257601\tepsilon: 6.11\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002691\talpha_max: 0.240857\tepsilon: 5.75\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.007605\talpha_max: 0.240857\tepsilon: 5.34\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.001607\talpha_max: 0.211954\tepsilon: 4.95\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.010963\talpha_max: 0.211954\tepsilon: 4.56\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.001848\talpha_max: 0.233149\tepsilon: 4.12\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.005055\talpha_max: 0.233149\tepsilon: 3.71\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.000855\talpha_max: 0.243641\tepsilon: 3.30\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002167\talpha_max: 0.243641\tepsilon: 2.89\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.000733\talpha_max: 0.268005\tepsilon: 2.48\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.000956\talpha_max: 0.268005\tepsilon: 2.07\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.000628\talpha_max: 0.280066\tepsilon: 1.66\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.000657\talpha_max: 0.280066\tepsilon: 1.25\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002208\talpha_max: 0.292669\tepsilon: 0.84\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.003298\talpha_max: 0.292669\tepsilon: 0.43\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.000278\talpha_max: 0.321935\tepsilon: 0.02\n",
      "Now is worker 3\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.057237\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.117935\talpha_max: 0.100000\tepsilon: 7.56\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.024165\talpha_max: 0.088532\tepsilon: 7.16\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.016394\talpha_max: 0.088532\tepsilon: 6.79\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.019639\talpha_max: 0.058431\tepsilon: 6.42\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.013331\talpha_max: 0.058431\tepsilon: 6.06\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.019130\talpha_max: 0.057847\tepsilon: 5.69\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.007686\talpha_max: 0.057847\tepsilon: 5.32\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.014325\talpha_max: 0.057268\tepsilon: 4.95\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.011876\talpha_max: 0.057268\tepsilon: 4.58\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.005010\talpha_max: 0.050396\tepsilon: 4.21\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.006196\talpha_max: 0.050396\tepsilon: 3.85\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004695\talpha_max: 0.052664\tepsilon: 3.44\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.010602\talpha_max: 0.052664\tepsilon: 3.05\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002760\talpha_max: 0.057931\tepsilon: 2.66\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.006273\talpha_max: 0.057931\tepsilon: 2.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003092\talpha_max: 0.047793\tepsilon: 1.83\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.010876\talpha_max: 0.047793\tepsilon: 1.42\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004978\talpha_max: 0.049943\tepsilon: 0.96\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.005322\talpha_max: 0.049943\tepsilon: 0.52\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002000\talpha_max: 0.054938\tepsilon: 0.05\n",
      "Now is worker 4\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.216496\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.062732\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.071779\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.013428\talpha_max: 0.110000\tepsilon: 6.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.042390\talpha_max: 0.121000\tepsilon: 6.60\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.021065\talpha_max: 0.121000\tepsilon: 6.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.073392\talpha_max: 0.133100\tepsilon: 5.90\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.010675\talpha_max: 0.133100\tepsilon: 5.55\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.071359\talpha_max: 0.146410\tepsilon: 5.16\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.005330\talpha_max: 0.146410\tepsilon: 4.79\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004376\talpha_max: 0.152998\tepsilon: 4.42\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.006317\talpha_max: 0.152998\tepsilon: 4.05\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003359\talpha_max: 0.168298\tepsilon: 3.69\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.003857\talpha_max: 0.168298\tepsilon: 3.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003382\talpha_max: 0.148102\tepsilon: 2.88\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002277\talpha_max: 0.148102\tepsilon: 2.45\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002859\talpha_max: 0.162913\tepsilon: 2.04\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002747\talpha_max: 0.162913\tepsilon: 1.63\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003441\talpha_max: 0.152323\tepsilon: 1.22\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.001577\talpha_max: 0.152323\tepsilon: 0.80\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.001600\talpha_max: 0.159178\tepsilon: 0.39\n",
      "Now is worker 5\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.014067\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.056713\talpha_max: 0.175096\tepsilon: 7.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.123760\talpha_max: 0.175096\tepsilon: 7.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.010199\talpha_max: 0.144454\tepsilon: 6.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.027236\talpha_max: 0.144454\tepsilon: 6.60\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.007313\talpha_max: 0.158899\tepsilon: 6.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003878\talpha_max: 0.158899\tepsilon: 5.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002848\talpha_max: 0.174789\tepsilon: 5.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.007588\talpha_max: 0.174789\tepsilon: 5.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002388\talpha_max: 0.192268\tepsilon: 4.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003280\talpha_max: 0.192268\tepsilon: 4.60\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.001039\talpha_max: 0.211495\tepsilon: 4.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002130\talpha_max: 0.211495\tepsilon: 3.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.001810\talpha_max: 0.232645\tepsilon: 3.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.001671\talpha_max: 0.232645\tepsilon: 3.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.001539\talpha_max: 0.243114\tepsilon: 2.88\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.001180\talpha_max: 0.243114\tepsilon: 2.53\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.001120\talpha_max: 0.200569\tepsilon: 2.18\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.001769\talpha_max: 0.200569\tepsilon: 1.83\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.001606\talpha_max: 0.220626\tepsilon: 1.48\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.001588\talpha_max: 0.220626\tepsilon: 1.13\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.001279\talpha_max: 0.218419\tepsilon: 0.78\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.001947\talpha_max: 0.218419\tepsilon: 0.43\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.000720\talpha_max: 0.240261\tepsilon: 0.08\n",
      "Now is worker 6\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.049606\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.073051\talpha_max: 0.105715\tepsilon: 7.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004867\talpha_max: 0.105715\tepsilon: 7.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.053839\talpha_max: 0.075586\tepsilon: 6.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.008802\talpha_max: 0.075586\tepsilon: 6.60\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.031050\talpha_max: 0.078988\tepsilon: 6.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.010830\talpha_max: 0.078988\tepsilon: 5.89\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.029205\talpha_max: 0.078198\tepsilon: 5.48\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.011294\talpha_max: 0.078198\tepsilon: 5.12\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.038678\talpha_max: 0.068814\tepsilon: 4.69\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.010221\talpha_max: 0.068814\tepsilon: 4.31\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.031123\talpha_max: 0.075695\tepsilon: 3.86\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.006758\talpha_max: 0.075695\tepsilon: 3.45\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.041394\talpha_max: 0.083265\tepsilon: 3.04\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002813\talpha_max: 0.083265\tepsilon: 2.63\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.014423\talpha_max: 0.091591\tepsilon: 2.22\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.005608\talpha_max: 0.091591\tepsilon: 1.75\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.010517\talpha_max: 0.085638\tepsilon: 1.31\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004315\talpha_max: 0.085638\tepsilon: 0.82\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.010801\talpha_max: 0.084782\tepsilon: 0.36\n",
      "Now is worker 7\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.207420\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.182841\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.114574\talpha_max: 0.083934\tepsilon: 7.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.048294\talpha_max: 0.083934\tepsilon: 6.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.051169\talpha_max: 0.092327\tepsilon: 6.60\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.028371\talpha_max: 0.092327\tepsilon: 6.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.030292\talpha_max: 0.086326\tepsilon: 5.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.019686\talpha_max: 0.086326\tepsilon: 5.53\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.035890\talpha_max: 0.094958\tepsilon: 5.16\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.013533\talpha_max: 0.094958\tepsilon: 4.79\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.012852\talpha_max: 0.104454\tepsilon: 4.38\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.011026\talpha_max: 0.104454\tepsilon: 3.99\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.014074\talpha_max: 0.114900\tepsilon: 3.56\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.006795\talpha_max: 0.114900\tepsilon: 3.15\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.009816\talpha_max: 0.113751\tepsilon: 2.74\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.003733\talpha_max: 0.113751\tepsilon: 2.33\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004802\talpha_max: 0.112613\tepsilon: 1.92\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.003436\talpha_max: 0.112613\tepsilon: 1.45\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.005985\talpha_max: 0.105293\tepsilon: 1.01\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.003520\talpha_max: 0.105293\tepsilon: 0.58\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003889\talpha_max: 0.098449\tepsilon: 0.14\n",
      "Now is worker 8\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.239639\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.049091\talpha_max: 0.108294\tepsilon: 7.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.202446\talpha_max: 0.108294\tepsilon: 7.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.015383\talpha_max: 0.119124\tepsilon: 6.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.066353\talpha_max: 0.119124\tepsilon: 6.56\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.015534\talpha_max: 0.117932\tepsilon: 6.16\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.055871\talpha_max: 0.117932\tepsilon: 5.79\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.006897\talpha_max: 0.129726\tepsilon: 5.38\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.024760\talpha_max: 0.129726\tepsilon: 4.99\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.004319\talpha_max: 0.107024\tepsilon: 4.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.007471\talpha_max: 0.107024\tepsilon: 4.17\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.003366\talpha_max: 0.111840\tepsilon: 3.76\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003570\talpha_max: 0.111840\tepsilon: 3.31\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002845\talpha_max: 0.123024\tepsilon: 2.82\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.013325\talpha_max: 0.123024\tepsilon: 2.36\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002343\talpha_max: 0.121793\tepsilon: 1.90\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.003223\talpha_max: 0.121793\tepsilon: 1.44\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002325\talpha_max: 0.133973\tepsilon: 0.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002599\talpha_max: 0.133973\tepsilon: 0.40\n",
      "Now is worker 9\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.130409\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.093386\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.043982\talpha_max: 0.082500\tepsilon: 7.27\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.077053\talpha_max: 0.082500\tepsilon: 6.93\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.063808\talpha_max: 0.086213\tepsilon: 6.60\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.023765\talpha_max: 0.086213\tepsilon: 6.27\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.024277\talpha_max: 0.094834\tepsilon: 5.93\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.019258\talpha_max: 0.094834\tepsilon: 5.56\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.008007\talpha_max: 0.099101\tepsilon: 5.18\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.016070\talpha_max: 0.099101\tepsilon: 4.81\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.007774\talpha_max: 0.109011\tepsilon: 4.44\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.006450\talpha_max: 0.109011\tepsilon: 4.07\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.006362\talpha_max: 0.119913\tepsilon: 3.70\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.014292\talpha_max: 0.119913\tepsilon: 3.33\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.025327\talpha_max: 0.131904\tepsilon: 2.97\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.006181\talpha_max: 0.131904\tepsilon: 2.60\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004229\talpha_max: 0.101566\tepsilon: 2.23\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.003764\talpha_max: 0.101566\tepsilon: 1.86\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.002223\talpha_max: 0.111723\tepsilon: 1.49\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.002624\talpha_max: 0.111723\tepsilon: 1.12\n",
      "Train rounds: 6 [0/60000 (0%)]\tLoss: 0.004114\talpha_max: 0.116750\tepsilon: 0.65\n",
      "Train rounds: 6 [300/60000 (0%)]\tLoss: 0.003884\talpha_max: 0.116750\tepsilon: 0.24\n",
      "\n",
      "Test set: Average loss: 0.1700, Accuracy: 9609/10000 (96%)\tepsilon: -0.00\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.649671\talpha_max: 0.100000\tepsilon: 7.90\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.344029\talpha_max: 0.109161\tepsilon: 7.55\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.254115\talpha_max: 0.109161\tepsilon: 7.20\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.162185\talpha_max: 0.084054\tepsilon: 6.85\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.091733\talpha_max: 0.084054\tepsilon: 6.50\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.100486\talpha_max: 0.083214\tepsilon: 6.11\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.085030\talpha_max: 0.083214\tepsilon: 5.74\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.065844\talpha_max: 0.091535\tepsilon: 5.37\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.037719\talpha_max: 0.091535\tepsilon: 4.96\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.044704\talpha_max: 0.090620\tepsilon: 4.53\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.011171\talpha_max: 0.090620\tepsilon: 4.12\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.054153\talpha_max: 0.089713\tepsilon: 3.71\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.008657\talpha_max: 0.089713\tepsilon: 3.30\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.040137\talpha_max: 0.093751\tepsilon: 2.88\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.010073\talpha_max: 0.093751\tepsilon: 2.47\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.031526\talpha_max: 0.097969\tepsilon: 2.06\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.006758\talpha_max: 0.097969\tepsilon: 1.65\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.022993\talpha_max: 0.102378\tepsilon: 1.24\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.015038\talpha_max: 0.102378\tepsilon: 0.83\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.016072\talpha_max: 0.112616\tepsilon: 0.42\n",
      "Now is worker 1\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.017042\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.317152\talpha_max: 0.123877\tepsilon: 7.60\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.021322\talpha_max: 0.123877\tepsilon: 7.27\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.112749\talpha_max: 0.122639\tepsilon: 6.93\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.032573\talpha_max: 0.122639\tepsilon: 6.56\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.023852\talpha_max: 0.134902\tepsilon: 6.18\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.008055\talpha_max: 0.134902\tepsilon: 5.81\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.034600\talpha_max: 0.103875\tepsilon: 5.44\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.006462\talpha_max: 0.103875\tepsilon: 5.07\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.007877\talpha_max: 0.102836\tepsilon: 4.70\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.006321\talpha_max: 0.102836\tepsilon: 4.33\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.005295\talpha_max: 0.096152\tepsilon: 3.97\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004763\talpha_max: 0.096152\tepsilon: 3.60\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.008361\talpha_max: 0.105767\tepsilon: 3.23\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004527\talpha_max: 0.105767\tepsilon: 2.81\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.036626\talpha_max: 0.098892\tepsilon: 2.42\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.005289\talpha_max: 0.098892\tepsilon: 2.03\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.005302\talpha_max: 0.108781\tepsilon: 1.64\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.002722\talpha_max: 0.108781\tepsilon: 1.25\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.004755\talpha_max: 0.113676\tepsilon: 0.86\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.003228\talpha_max: 0.113676\tepsilon: 0.42\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.003043\talpha_max: 0.118792\tepsilon: 0.01\n",
      "Now is worker 2\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.313899\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.079079\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.101092\talpha_max: 0.130671\tepsilon: 7.27\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.013721\talpha_max: 0.130671\tepsilon: 6.93\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.070702\talpha_max: 0.114991\tepsilon: 6.60\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.016961\talpha_max: 0.114991\tepsilon: 6.27\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.028154\talpha_max: 0.107516\tepsilon: 5.93\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.011068\talpha_max: 0.107516\tepsilon: 5.55\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.013701\talpha_max: 0.118268\tepsilon: 5.20\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.004632\talpha_max: 0.118268\tepsilon: 4.81\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.006523\talpha_max: 0.117085\tepsilon: 4.44\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.004380\talpha_max: 0.117085\tepsilon: 4.08\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.007234\talpha_max: 0.128794\tepsilon: 3.71\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.003085\talpha_max: 0.128794\tepsilon: 3.30\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.009196\talpha_max: 0.141673\tepsilon: 2.91\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.001586\talpha_max: 0.141673\tepsilon: 2.52\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.006753\talpha_max: 0.148048\tepsilon: 2.13\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.002529\talpha_max: 0.148048\tepsilon: 1.74\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004891\talpha_max: 0.162853\tepsilon: 1.35\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.001184\talpha_max: 0.162853\tepsilon: 0.91\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004194\talpha_max: 0.143311\tepsilon: 0.50\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.001500\talpha_max: 0.143311\tepsilon: 0.09\n",
      "Now is worker 3\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.024361\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.255241\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.059685\talpha_max: 0.110000\tepsilon: 7.22\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.375514\talpha_max: 0.110000\tepsilon: 6.87\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.015184\talpha_max: 0.121000\tepsilon: 6.52\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.159974\talpha_max: 0.121000\tepsilon: 6.17\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.016583\talpha_max: 0.126445\tepsilon: 5.82\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.092580\talpha_max: 0.126445\tepsilon: 5.43\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.006432\talpha_max: 0.125181\tepsilon: 5.06\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.098210\talpha_max: 0.125181\tepsilon: 4.69\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.012028\talpha_max: 0.123929\tepsilon: 4.32\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.039617\talpha_max: 0.123929\tepsilon: 3.92\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.007542\talpha_max: 0.122689\tepsilon: 3.53\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.022446\talpha_max: 0.122689\tepsilon: 3.14\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.003659\talpha_max: 0.134958\tepsilon: 2.75\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.018167\talpha_max: 0.134958\tepsilon: 2.36\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.005773\talpha_max: 0.133609\tepsilon: 1.97\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.004280\talpha_max: 0.133609\tepsilon: 1.59\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.001995\talpha_max: 0.146970\tepsilon: 1.20\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.008743\talpha_max: 0.146970\tepsilon: 0.75\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.002079\talpha_max: 0.161667\tepsilon: 0.34\n",
      "Now is worker 4\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.113744\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.021091\talpha_max: 0.115592\tepsilon: 7.60\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.029793\talpha_max: 0.115592\tepsilon: 7.27\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.006081\talpha_max: 0.108078\tepsilon: 6.93\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.022280\talpha_max: 0.108078\tepsilon: 6.55\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.002295\talpha_max: 0.112942\tepsilon: 6.20\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.018363\talpha_max: 0.112942\tepsilon: 5.85\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.000927\talpha_max: 0.111812\tepsilon: 5.47\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.006268\talpha_max: 0.111812\tepsilon: 5.10\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.008937\talpha_max: 0.122994\tepsilon: 4.73\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.007422\talpha_max: 0.122994\tepsilon: 4.31\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.001581\talpha_max: 0.135293\tepsilon: 3.92\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.010921\talpha_max: 0.135293\tepsilon: 3.53\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.000688\talpha_max: 0.141381\tepsilon: 3.14\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004649\talpha_max: 0.141381\tepsilon: 2.71\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.001211\talpha_max: 0.155519\tepsilon: 2.24\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.008627\talpha_max: 0.155519\tepsilon: 1.76\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.001074\talpha_max: 0.171071\tepsilon: 1.25\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.002725\talpha_max: 0.171071\tepsilon: 0.72\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.000454\talpha_max: 0.188178\tepsilon: 0.20\n",
      "Now is worker 5\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.520941\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.104559\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.292482\talpha_max: 0.175947\tepsilon: 7.27\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.046127\talpha_max: 0.175947\tepsilon: 6.93\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.268909\talpha_max: 0.154833\tepsilon: 6.56\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.002740\talpha_max: 0.154833\tepsilon: 6.21\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.017222\talpha_max: 0.144769\tepsilon: 5.82\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.003926\talpha_max: 0.144769\tepsilon: 5.45\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.009028\talpha_max: 0.143321\tepsilon: 5.09\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.002584\talpha_max: 0.143321\tepsilon: 4.72\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.008251\talpha_max: 0.126123\tepsilon: 4.35\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.004693\talpha_max: 0.126123\tepsilon: 3.98\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.003733\talpha_max: 0.104051\tepsilon: 3.56\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.002496\talpha_max: 0.104051\tepsilon: 3.17\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.007596\talpha_max: 0.108733\tepsilon: 2.79\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.001874\talpha_max: 0.108733\tepsilon: 2.40\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.005105\talpha_max: 0.083725\tepsilon: 2.01\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.002299\talpha_max: 0.083725\tepsilon: 1.58\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004503\talpha_max: 0.092097\tepsilon: 1.17\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.000962\talpha_max: 0.092097\tepsilon: 0.76\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004949\talpha_max: 0.086111\tepsilon: 0.25\n",
      "Now is worker 6\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.050801\talpha_max: 0.100000\tepsilon: 7.90\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.378825\talpha_max: 0.099000\tepsilon: 7.55\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.007928\talpha_max: 0.099000\tepsilon: 7.20\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.291351\talpha_max: 0.087120\tepsilon: 6.85\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.005103\talpha_max: 0.087120\tepsilon: 6.50\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.173686\talpha_max: 0.076666\tepsilon: 6.15\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.005724\talpha_max: 0.076666\tepsilon: 5.80\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.120891\talpha_max: 0.075899\tepsilon: 5.41\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.003779\talpha_max: 0.075899\tepsilon: 5.04\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.091071\talpha_max: 0.083489\tepsilon: 4.67\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.005201\talpha_max: 0.083489\tepsilon: 4.30\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.052813\talpha_max: 0.091838\tepsilon: 3.94\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004186\talpha_max: 0.091838\tepsilon: 3.57\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.040193\talpha_max: 0.085868\tepsilon: 3.20\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.003438\talpha_max: 0.085868\tepsilon: 2.83\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.027747\talpha_max: 0.094455\tepsilon: 2.46\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004571\talpha_max: 0.094455\tepsilon: 2.09\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.033745\talpha_max: 0.098706\tepsilon: 1.68\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.005762\talpha_max: 0.098706\tepsilon: 1.25\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.006612\talpha_max: 0.108576\tepsilon: 0.84\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.002538\talpha_max: 0.108576\tepsilon: 0.43\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.013187\talpha_max: 0.119434\tepsilon: 0.02\n",
      "Now is worker 7\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.105657\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.196513\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.008980\talpha_max: 0.118239\tepsilon: 7.27\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.065962\talpha_max: 0.118239\tepsilon: 6.93\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.015650\talpha_max: 0.110554\tepsilon: 6.55\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.009872\talpha_max: 0.110554\tepsilon: 6.17\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.010422\talpha_max: 0.115529\tepsilon: 5.80\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.013081\talpha_max: 0.115529\tepsilon: 5.33\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.009846\talpha_max: 0.127082\tepsilon: 4.88\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.007729\talpha_max: 0.127082\tepsilon: 4.45\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.008994\talpha_max: 0.097853\tepsilon: 4.01\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.006990\talpha_max: 0.097853\tepsilon: 3.58\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004849\talpha_max: 0.080729\tepsilon: 3.14\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.005124\talpha_max: 0.080729\tepsilon: 2.71\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.005057\talpha_max: 0.084361\tepsilon: 2.27\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.003982\talpha_max: 0.084361\tepsilon: 1.71\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.003420\talpha_max: 0.092798\tepsilon: 1.22\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.004415\talpha_max: 0.092798\tepsilon: 0.68\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.006002\talpha_max: 0.102077\tepsilon: 0.15\n",
      "Now is worker 8\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.220056\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.795539\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.031591\talpha_max: 0.099000\tepsilon: 7.27\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.621722\talpha_max: 0.099000\tepsilon: 6.93\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.021979\talpha_max: 0.081675\tepsilon: 6.60\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.407679\talpha_max: 0.081675\tepsilon: 6.22\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.017382\talpha_max: 0.085350\tepsilon: 5.87\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.176440\talpha_max: 0.085350\tepsilon: 5.47\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.019121\talpha_max: 0.089191\tepsilon: 5.05\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.111542\talpha_max: 0.089191\tepsilon: 4.66\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.021895\talpha_max: 0.088299\tepsilon: 4.22\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.047549\talpha_max: 0.088299\tepsilon: 3.75\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.006918\talpha_max: 0.097129\tepsilon: 3.28\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.046058\talpha_max: 0.097129\tepsilon: 2.82\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.008144\talpha_max: 0.058763\tepsilon: 2.31\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.023512\talpha_max: 0.058763\tepsilon: 1.76\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.009272\talpha_max: 0.064639\tepsilon: 1.24\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.022047\talpha_max: 0.064639\tepsilon: 0.72\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.009740\talpha_max: 0.067548\tepsilon: 0.15\n",
      "Now is worker 9\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.175607\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.030331\talpha_max: 0.088000\tepsilon: 7.60\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.046061\talpha_max: 0.088000\tepsilon: 7.27\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.021360\talpha_max: 0.077440\tepsilon: 6.93\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.046513\talpha_max: 0.077440\tepsilon: 6.52\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.018491\talpha_max: 0.076666\tepsilon: 6.15\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.014494\talpha_max: 0.076666\tepsilon: 5.78\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.004447\talpha_max: 0.080116\tepsilon: 5.41\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.012394\talpha_max: 0.080116\tepsilon: 4.99\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.004529\talpha_max: 0.074908\tepsilon: 4.60\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.003860\talpha_max: 0.074908\tepsilon: 4.21\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.003074\talpha_max: 0.082399\tepsilon: 3.83\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.002843\talpha_max: 0.082399\tepsilon: 3.44\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.004137\talpha_max: 0.086107\tepsilon: 3.05\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.002538\talpha_max: 0.086107\tepsilon: 2.66\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.002400\talpha_max: 0.085246\tepsilon: 2.23\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.004373\talpha_max: 0.085246\tepsilon: 1.78\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.005364\talpha_max: 0.042197\tepsilon: 1.34\n",
      "Train rounds: 7 [0/60000 (0%)]\tLoss: 0.005326\talpha_max: 0.042197\tepsilon: 0.91\n",
      "Train rounds: 7 [300/60000 (0%)]\tLoss: 0.002148\talpha_max: 0.046416\tepsilon: 0.47\n",
      "\n",
      "Test set: Average loss: 0.1601, Accuracy: 9630/10000 (96%)\tepsilon: -0.01\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.147316\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.198256\talpha_max: 0.110000\tepsilon: 7.56\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.008297\talpha_max: 0.110000\tepsilon: 7.21\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.105306\talpha_max: 0.108900\tepsilon: 6.86\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.011805\talpha_max: 0.108900\tepsilon: 6.45\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.033235\talpha_max: 0.119790\tepsilon: 5.99\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.015005\talpha_max: 0.119790\tepsilon: 5.53\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.013080\talpha_max: 0.125181\tepsilon: 5.09\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.004847\talpha_max: 0.125181\tepsilon: 4.66\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.014226\talpha_max: 0.137699\tepsilon: 4.22\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.005031\talpha_max: 0.137699\tepsilon: 3.79\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.009145\talpha_max: 0.151468\tepsilon: 3.29\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003681\talpha_max: 0.151468\tepsilon: 2.83\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.009727\talpha_max: 0.124961\tepsilon: 2.37\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003575\talpha_max: 0.124961\tepsilon: 1.86\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002250\talpha_max: 0.130585\tepsilon: 1.37\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001740\talpha_max: 0.130585\tepsilon: 0.87\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002432\talpha_max: 0.143643\tepsilon: 0.38\n",
      "Now is worker 1\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.104459\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.127008\talpha_max: 0.150107\tepsilon: 7.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.081724\talpha_max: 0.150107\tepsilon: 7.27\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.005205\talpha_max: 0.156862\tepsilon: 6.89\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.008654\talpha_max: 0.156862\tepsilon: 6.54\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002778\talpha_max: 0.172548\tepsilon: 6.19\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.018417\talpha_max: 0.172548\tepsilon: 5.80\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002953\talpha_max: 0.189803\tepsilon: 5.43\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.007370\talpha_max: 0.189803\tepsilon: 5.06\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002066\talpha_max: 0.208783\tepsilon: 4.69\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.002882\talpha_max: 0.208783\tepsilon: 4.33\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001829\talpha_max: 0.218179\tepsilon: 3.90\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001978\talpha_max: 0.218179\tepsilon: 3.51\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002417\talpha_max: 0.227997\tepsilon: 3.13\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001431\talpha_max: 0.227997\tepsilon: 2.68\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002442\talpha_max: 0.250796\tepsilon: 2.27\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000828\talpha_max: 0.250796\tepsilon: 1.81\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000494\talpha_max: 0.262082\tepsilon: 1.38\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001769\talpha_max: 0.262082\tepsilon: 0.89\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000514\talpha_max: 0.288290\tepsilon: 0.37\n",
      "Now is worker 2\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.378506\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.044485\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.195384\talpha_max: 0.301263\tepsilon: 7.27\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.036713\talpha_max: 0.301263\tepsilon: 6.89\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.061208\talpha_max: 0.331390\tepsilon: 6.54\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.004331\talpha_max: 0.331390\tepsilon: 6.19\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.052351\talpha_max: 0.364529\tepsilon: 5.84\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001417\talpha_max: 0.364529\tepsilon: 5.49\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.009116\talpha_max: 0.320785\tepsilon: 5.14\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002091\talpha_max: 0.320785\tepsilon: 4.79\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.007284\talpha_max: 0.317577\tepsilon: 4.44\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000656\talpha_max: 0.317577\tepsilon: 4.09\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001722\talpha_max: 0.331868\tepsilon: 3.74\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000335\talpha_max: 0.331868\tepsilon: 3.34\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003658\talpha_max: 0.328550\tepsilon: 2.94\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000673\talpha_max: 0.328550\tepsilon: 2.50\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000829\talpha_max: 0.343334\tepsilon: 2.03\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000279\talpha_max: 0.343334\tepsilon: 1.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001290\talpha_max: 0.377668\tepsilon: 1.16\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000368\talpha_max: 0.377668\tepsilon: 0.73\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001038\talpha_max: 0.353119\tepsilon: 0.29\n",
      "Now is worker 3\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.642812\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.398576\talpha_max: 0.388431\tepsilon: 7.56\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.203797\talpha_max: 0.388431\tepsilon: 7.21\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.085816\talpha_max: 0.384547\tepsilon: 6.86\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.055422\talpha_max: 0.384547\tepsilon: 6.47\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.027261\talpha_max: 0.401852\tepsilon: 6.10\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.033433\talpha_max: 0.401852\tepsilon: 5.69\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.004369\talpha_max: 0.442037\tepsilon: 5.30\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001720\talpha_max: 0.442037\tepsilon: 4.91\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000963\talpha_max: 0.486241\tepsilon: 4.47\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001207\talpha_max: 0.486241\tepsilon: 4.06\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000616\talpha_max: 0.508121\tepsilon: 3.65\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000970\talpha_max: 0.508121\tepsilon: 3.24\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000456\talpha_max: 0.558934\tepsilon: 2.83\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000769\talpha_max: 0.558934\tepsilon: 2.42\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000447\talpha_max: 0.584086\tepsilon: 2.00\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000552\talpha_max: 0.584086\tepsilon: 1.55\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001094\talpha_max: 0.642494\tepsilon: 1.12\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000665\talpha_max: 0.642494\tepsilon: 0.68\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000421\talpha_max: 0.600732\tepsilon: 0.25\n",
      "Now is worker 4\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.068921\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.542340\talpha_max: 0.495604\tepsilon: 7.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.628611\talpha_max: 0.495604\tepsilon: 7.27\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.092452\talpha_max: 0.517906\tepsilon: 6.93\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.122030\talpha_max: 0.517906\tepsilon: 6.60\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.010288\talpha_max: 0.569697\tepsilon: 6.27\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.144799\talpha_max: 0.569697\tepsilon: 5.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.010162\talpha_max: 0.595333\tepsilon: 5.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.024874\talpha_max: 0.595333\tepsilon: 5.27\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.020212\talpha_max: 0.589380\tepsilon: 4.93\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.001052\talpha_max: 0.589380\tepsilon: 4.60\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001085\talpha_max: 0.648318\tepsilon: 4.27\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000997\talpha_max: 0.648318\tepsilon: 3.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000824\talpha_max: 0.677492\tepsilon: 3.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000389\talpha_max: 0.677492\tepsilon: 3.27\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000895\talpha_max: 0.558931\tepsilon: 2.93\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000421\talpha_max: 0.558931\tepsilon: 2.60\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000490\talpha_max: 0.614824\tepsilon: 2.23\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000242\talpha_max: 0.614824\tepsilon: 1.83\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000400\talpha_max: 0.608676\tepsilon: 1.41\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000387\talpha_max: 0.608676\tepsilon: 1.02\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000479\talpha_max: 0.636066\tepsilon: 0.63\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000139\talpha_max: 0.636066\tepsilon: 0.24\n",
      "Now is worker 5\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.009497\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.029383\talpha_max: 0.100000\tepsilon: 7.51\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003756\talpha_max: 0.077000\tepsilon: 7.14\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.003509\talpha_max: 0.077000\tepsilon: 6.73\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.004336\talpha_max: 0.084700\tepsilon: 6.34\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002285\talpha_max: 0.084700\tepsilon: 5.91\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.010260\talpha_max: 0.093170\tepsilon: 5.44\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002820\talpha_max: 0.093170\tepsilon: 5.01\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.012804\talpha_max: 0.102487\tepsilon: 4.57\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002757\talpha_max: 0.102487\tepsilon: 4.08\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003817\talpha_max: 0.112736\tepsilon: 3.61\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001536\talpha_max: 0.112736\tepsilon: 3.10\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.002709\talpha_max: 0.124009\tepsilon: 2.61\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001839\talpha_max: 0.124009\tepsilon: 2.12\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003460\talpha_max: 0.122769\tepsilon: 1.63\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000591\talpha_max: 0.122769\tepsilon: 1.13\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.002183\talpha_max: 0.114789\tepsilon: 0.64\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.000465\talpha_max: 0.114789\tepsilon: 0.15\n",
      "Now is worker 6\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.121896\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.247126\talpha_max: 0.113641\tepsilon: 7.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.095679\talpha_max: 0.113641\tepsilon: 7.27\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.038295\talpha_max: 0.125005\tepsilon: 6.89\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.062633\talpha_max: 0.125005\tepsilon: 6.50\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.013147\talpha_max: 0.130631\tepsilon: 6.13\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.040396\talpha_max: 0.130631\tepsilon: 5.76\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.005000\talpha_max: 0.136509\tepsilon: 5.39\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.014266\talpha_max: 0.136509\tepsilon: 5.03\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.003804\talpha_max: 0.142652\tepsilon: 4.66\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.004257\talpha_max: 0.142652\tepsilon: 4.29\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002542\talpha_max: 0.141225\tepsilon: 3.83\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.002294\talpha_max: 0.141225\tepsilon: 3.42\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.003099\talpha_max: 0.139813\tepsilon: 3.01\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003682\talpha_max: 0.139813\tepsilon: 2.60\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.003867\talpha_max: 0.130725\tepsilon: 2.19\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.002733\talpha_max: 0.130725\tepsilon: 1.77\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.003134\talpha_max: 0.129418\tepsilon: 1.32\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003935\talpha_max: 0.129418\tepsilon: 0.82\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001361\talpha_max: 0.135242\tepsilon: 0.36\n",
      "Now is worker 7\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.077552\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.308270\talpha_max: 0.133889\tepsilon: 7.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.080841\talpha_max: 0.133889\tepsilon: 7.27\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.101662\talpha_max: 0.147278\tepsilon: 6.89\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.013668\talpha_max: 0.147278\tepsilon: 6.54\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.018240\talpha_max: 0.153906\tepsilon: 6.14\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.012646\talpha_max: 0.153906\tepsilon: 5.77\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.012181\talpha_max: 0.160832\tepsilon: 5.40\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.004629\talpha_max: 0.160832\tepsilon: 5.03\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.006409\talpha_max: 0.168069\tepsilon: 4.66\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.005595\talpha_max: 0.168069\tepsilon: 4.30\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.004518\talpha_max: 0.175632\tepsilon: 3.93\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003172\talpha_max: 0.175632\tepsilon: 3.51\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.003212\talpha_max: 0.183536\tepsilon: 3.12\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.002257\talpha_max: 0.183536\tepsilon: 2.73\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002840\talpha_max: 0.141322\tepsilon: 2.34\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.002961\talpha_max: 0.141322\tepsilon: 1.96\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001391\talpha_max: 0.132137\tepsilon: 1.57\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.002899\talpha_max: 0.132137\tepsilon: 1.18\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001698\talpha_max: 0.145350\tepsilon: 0.79\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.000941\talpha_max: 0.145350\tepsilon: 0.40\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.001994\talpha_max: 0.135902\tepsilon: 0.01\n",
      "Now is worker 8\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.059782\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.075164\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.016685\talpha_max: 0.093500\tepsilon: 7.14\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.017310\talpha_max: 0.093500\tepsilon: 6.66\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.027849\talpha_max: 0.102850\tepsilon: 6.23\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.010962\talpha_max: 0.102850\tepsilon: 5.79\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.009075\talpha_max: 0.113135\tepsilon: 5.36\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.007554\talpha_max: 0.113135\tepsilon: 4.92\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.014476\talpha_max: 0.118226\tepsilon: 4.45\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.005534\talpha_max: 0.118226\tepsilon: 3.98\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003927\talpha_max: 0.117044\tepsilon: 3.52\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.002860\talpha_max: 0.117044\tepsilon: 3.06\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.004005\talpha_max: 0.115873\tepsilon: 2.60\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.003591\talpha_max: 0.115873\tepsilon: 2.03\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003999\talpha_max: 0.121088\tepsilon: 1.51\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.004348\talpha_max: 0.121088\tepsilon: 0.98\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003688\talpha_max: 0.133196\tepsilon: 0.46\n",
      "Now is worker 9\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.192634\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.497103\talpha_max: 0.117213\tepsilon: 7.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.014065\talpha_max: 0.117213\tepsilon: 7.27\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.200244\talpha_max: 0.103147\tepsilon: 6.93\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.025395\talpha_max: 0.103147\tepsilon: 6.60\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.138867\talpha_max: 0.113462\tepsilon: 6.27\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.034259\talpha_max: 0.113462\tepsilon: 5.93\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.026169\talpha_max: 0.074885\tepsilon: 5.60\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.012020\talpha_max: 0.074885\tepsilon: 5.23\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.034829\talpha_max: 0.082373\tepsilon: 4.88\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.012562\talpha_max: 0.082373\tepsilon: 4.53\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.007409\talpha_max: 0.090611\tepsilon: 4.18\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.004937\talpha_max: 0.090611\tepsilon: 3.72\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.011514\talpha_max: 0.074754\tepsilon: 3.34\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.004269\talpha_max: 0.074754\tepsilon: 2.89\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.005357\talpha_max: 0.074006\tepsilon: 2.48\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003797\talpha_max: 0.074006\tepsilon: 2.07\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.007645\talpha_max: 0.081407\tepsilon: 1.66\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.003205\talpha_max: 0.081407\tepsilon: 1.25\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.003472\talpha_max: 0.080593\tepsilon: 0.84\n",
      "Train rounds: 8 [0/60000 (0%)]\tLoss: 0.002124\talpha_max: 0.080593\tepsilon: 0.43\n",
      "Train rounds: 8 [300/60000 (0%)]\tLoss: 0.007842\talpha_max: 0.066489\tepsilon: 0.02\n",
      "\n",
      "Test set: Average loss: 0.1503, Accuracy: 9646/10000 (96%)\tepsilon: -0.03\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.320193\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.022607\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.096124\talpha_max: 0.110000\tepsilon: 7.23\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002953\talpha_max: 0.110000\tepsilon: 6.88\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.083591\talpha_max: 0.114950\tepsilon: 6.53\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.003208\talpha_max: 0.114950\tepsilon: 6.18\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.012947\talpha_max: 0.113801\tepsilon: 5.83\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001931\talpha_max: 0.113801\tepsilon: 5.48\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.003354\talpha_max: 0.125181\tepsilon: 5.13\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001712\talpha_max: 0.125181\tepsilon: 4.78\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002190\talpha_max: 0.137699\tepsilon: 4.43\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001096\talpha_max: 0.137699\tepsilon: 4.08\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.004015\talpha_max: 0.143895\tepsilon: 3.73\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001615\talpha_max: 0.143895\tepsilon: 3.38\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001861\talpha_max: 0.158285\tepsilon: 3.03\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001593\talpha_max: 0.158285\tepsilon: 2.68\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002751\talpha_max: 0.174113\tepsilon: 2.33\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002202\talpha_max: 0.174113\tepsilon: 1.98\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001076\talpha_max: 0.191524\tepsilon: 1.63\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001961\talpha_max: 0.191524\tepsilon: 1.28\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.003484\talpha_max: 0.179075\tepsilon: 0.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001091\talpha_max: 0.179075\tepsilon: 0.54\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001219\talpha_max: 0.157586\tepsilon: 0.17\n",
      "Now is worker 1\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.084584\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.401083\talpha_max: 0.173345\tepsilon: 7.56\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.038622\talpha_max: 0.173345\tepsilon: 7.16\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.019532\talpha_max: 0.181145\tepsilon: 6.79\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.041922\talpha_max: 0.181145\tepsilon: 6.42\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.005379\talpha_max: 0.199260\tepsilon: 6.05\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.007181\talpha_max: 0.199260\tepsilon: 5.68\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.004191\talpha_max: 0.219186\tepsilon: 5.32\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.005233\talpha_max: 0.219186\tepsilon: 4.95\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.003255\talpha_max: 0.216994\tepsilon: 4.58\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002208\talpha_max: 0.216994\tepsilon: 4.16\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002281\talpha_max: 0.238693\tepsilon: 3.77\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.005817\talpha_max: 0.238693\tepsilon: 3.38\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001624\talpha_max: 0.236306\tepsilon: 2.99\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001819\talpha_max: 0.236306\tepsilon: 2.55\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.000820\talpha_max: 0.259937\tepsilon: 2.14\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001353\talpha_max: 0.259937\tepsilon: 1.73\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.000469\talpha_max: 0.243041\tepsilon: 1.32\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001153\talpha_max: 0.243041\tepsilon: 0.91\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.000787\talpha_max: 0.213876\tepsilon: 0.50\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002287\talpha_max: 0.213876\tepsilon: 0.09\n",
      "Now is worker 2\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.018275\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.185768\talpha_max: 0.235264\tepsilon: 7.60\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.013631\talpha_max: 0.235264\tepsilon: 7.27\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.116241\talpha_max: 0.245851\tepsilon: 6.88\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.106267\talpha_max: 0.245851\tepsilon: 6.53\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.014287\talpha_max: 0.270436\tepsilon: 6.18\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.004459\talpha_max: 0.270436\tepsilon: 5.79\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.008123\talpha_max: 0.252857\tepsilon: 5.38\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001677\talpha_max: 0.252857\tepsilon: 4.95\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002669\talpha_max: 0.278143\tepsilon: 4.44\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000983\talpha_max: 0.278143\tepsilon: 3.98\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.004666\talpha_max: 0.275362\tepsilon: 3.47\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001431\talpha_max: 0.275362\tepsilon: 2.98\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002038\talpha_max: 0.272608\tepsilon: 2.49\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000585\talpha_max: 0.272608\tepsilon: 1.99\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001064\talpha_max: 0.299869\tepsilon: 1.50\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000511\talpha_max: 0.299869\tepsilon: 1.01\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001585\talpha_max: 0.313363\tepsilon: 0.52\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001841\talpha_max: 0.313363\tepsilon: 0.03\n",
      "Now is worker 3\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.196048\talpha_max: 0.100000\tepsilon: 7.90\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.753577\talpha_max: 0.292995\tepsilon: 7.55\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.077733\talpha_max: 0.292995\tepsilon: 7.11\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.469843\talpha_max: 0.290065\tepsilon: 6.72\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.008354\talpha_max: 0.290065\tepsilon: 6.33\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.048981\talpha_max: 0.303117\tepsilon: 5.94\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.008513\talpha_max: 0.303117\tepsilon: 5.55\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.021166\talpha_max: 0.233400\tepsilon: 5.16\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001098\talpha_max: 0.233400\tepsilon: 4.78\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002085\talpha_max: 0.256741\tepsilon: 4.35\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001537\talpha_max: 0.256741\tepsilon: 3.94\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001290\talpha_max: 0.225932\tepsilon: 3.53\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000603\talpha_max: 0.225932\tepsilon: 3.12\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001404\talpha_max: 0.248525\tepsilon: 2.71\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000585\talpha_max: 0.248525\tepsilon: 2.19\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001289\talpha_max: 0.259708\tepsilon: 1.73\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000362\talpha_max: 0.259708\tepsilon: 1.20\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.000407\talpha_max: 0.214259\tepsilon: 0.71\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000319\talpha_max: 0.214259\tepsilon: 0.22\n",
      "Now is worker 4\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.019680\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.281173\talpha_max: 0.100000\tepsilon: 7.55\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.010863\talpha_max: 0.135460\tepsilon: 7.20\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.004560\talpha_max: 0.135460\tepsilon: 6.85\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.011538\talpha_max: 0.141556\tepsilon: 6.50\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.004577\talpha_max: 0.141556\tepsilon: 5.87\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002447\talpha_max: 0.147926\tepsilon: 5.38\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.004440\talpha_max: 0.147926\tepsilon: 4.89\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001924\talpha_max: 0.138311\tepsilon: 4.40\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.003343\talpha_max: 0.138311\tepsilon: 3.91\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.010308\talpha_max: 0.121713\tepsilon: 3.36\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001812\talpha_max: 0.121713\tepsilon: 2.83\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002806\talpha_max: 0.133885\tepsilon: 2.31\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.004182\talpha_max: 0.133885\tepsilon: 1.79\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001792\talpha_max: 0.139910\tepsilon: 1.26\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001560\talpha_max: 0.139910\tepsilon: 0.74\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001174\talpha_max: 0.146206\tepsilon: 0.21\n",
      "Now is worker 5\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001330\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.218153\talpha_max: 0.160826\tepsilon: 7.60\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.077805\talpha_max: 0.160826\tepsilon: 7.22\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.007940\talpha_max: 0.176909\tepsilon: 6.87\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001940\talpha_max: 0.176909\tepsilon: 6.52\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.025576\talpha_max: 0.194600\tepsilon: 6.17\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.005201\talpha_max: 0.194600\tepsilon: 5.77\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.007030\talpha_max: 0.214060\tepsilon: 5.41\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000658\talpha_max: 0.214060\tepsilon: 5.04\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002505\talpha_max: 0.235465\tepsilon: 4.67\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000495\talpha_max: 0.235465\tepsilon: 4.30\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001092\talpha_max: 0.207210\tepsilon: 3.93\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000404\talpha_max: 0.207210\tepsilon: 3.56\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002404\talpha_max: 0.227931\tepsilon: 3.20\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000256\talpha_max: 0.227931\tepsilon: 2.78\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001025\talpha_max: 0.238187\tepsilon: 2.39\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000565\talpha_max: 0.238187\tepsilon: 1.96\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.003401\talpha_max: 0.235806\tepsilon: 1.55\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000188\talpha_max: 0.235806\tepsilon: 1.09\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001082\talpha_max: 0.259386\tepsilon: 0.65\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000236\talpha_max: 0.259386\tepsilon: 0.22\n",
      "Now is worker 6\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.100057\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.270012\talpha_max: 0.256792\tepsilon: 7.56\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.195524\talpha_max: 0.256792\tepsilon: 7.18\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.026102\talpha_max: 0.225977\tepsilon: 6.81\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.014363\talpha_max: 0.225977\tepsilon: 6.44\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.006963\talpha_max: 0.248575\tepsilon: 6.07\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.003692\talpha_max: 0.248575\tepsilon: 5.65\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.013329\talpha_max: 0.232418\tepsilon: 5.26\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.004912\talpha_max: 0.232418\tepsilon: 4.82\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001925\talpha_max: 0.191744\tepsilon: 4.41\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002280\talpha_max: 0.191744\tepsilon: 3.96\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002456\talpha_max: 0.189827\tepsilon: 3.47\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002057\talpha_max: 0.189827\tepsilon: 3.01\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001657\talpha_max: 0.146167\tepsilon: 2.55\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001173\talpha_max: 0.146167\tepsilon: 2.08\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002121\talpha_max: 0.152744\tepsilon: 1.58\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000875\talpha_max: 0.152744\tepsilon: 1.08\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001162\talpha_max: 0.151217\tepsilon: 0.55\n",
      "Now is worker 7\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.225888\talpha_max: 0.100000\tepsilon: 7.90\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.212409\talpha_max: 0.158022\tepsilon: 7.55\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.053327\talpha_max: 0.158022\tepsilon: 7.20\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.031822\talpha_max: 0.165133\tepsilon: 6.85\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.064413\talpha_max: 0.165133\tepsilon: 6.50\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.010011\talpha_max: 0.172564\tepsilon: 6.15\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.011020\talpha_max: 0.172564\tepsilon: 5.80\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.007028\talpha_max: 0.189820\tepsilon: 5.45\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.009809\talpha_max: 0.189820\tepsilon: 5.05\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001830\talpha_max: 0.198362\tepsilon: 4.68\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.007016\talpha_max: 0.198362\tepsilon: 4.31\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001199\talpha_max: 0.185468\tepsilon: 3.95\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.004642\talpha_max: 0.185468\tepsilon: 3.54\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002375\talpha_max: 0.204015\tepsilon: 3.10\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002103\talpha_max: 0.204015\tepsilon: 2.69\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001027\talpha_max: 0.224417\tepsilon: 2.28\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001840\talpha_max: 0.224417\tepsilon: 1.87\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.000594\talpha_max: 0.234515\tepsilon: 1.40\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.001352\talpha_max: 0.234515\tepsilon: 0.92\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.000555\talpha_max: 0.257967\tepsilon: 0.46\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.004071\talpha_max: 0.257967\tepsilon: 0.00\n",
      "Now is worker 8\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.023811\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.043009\talpha_max: 0.269575\tepsilon: 7.60\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.034017\talpha_max: 0.269575\tepsilon: 7.27\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.019619\talpha_max: 0.296533\tepsilon: 6.93\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002525\talpha_max: 0.296533\tepsilon: 6.60\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.005939\talpha_max: 0.244640\tepsilon: 6.27\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000963\talpha_max: 0.244640\tepsilon: 5.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002782\talpha_max: 0.269104\tepsilon: 5.60\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000904\talpha_max: 0.269104\tepsilon: 5.27\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002289\talpha_max: 0.266413\tepsilon: 4.85\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000829\talpha_max: 0.266413\tepsilon: 4.48\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002132\talpha_max: 0.278401\tepsilon: 4.07\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000537\talpha_max: 0.278401\tepsilon: 3.62\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001595\talpha_max: 0.290929\tepsilon: 3.21\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000837\talpha_max: 0.290929\tepsilon: 2.80\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001795\talpha_max: 0.272019\tepsilon: 2.39\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000455\talpha_max: 0.272019\tepsilon: 1.98\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.001547\talpha_max: 0.299221\tepsilon: 1.51\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000297\talpha_max: 0.299221\tepsilon: 1.02\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.000730\talpha_max: 0.312686\tepsilon: 0.56\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.000178\talpha_max: 0.312686\tepsilon: 0.10\n",
      "Now is worker 9\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.256231\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.194737\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.079349\talpha_max: 0.143773\tepsilon: 7.23\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.106218\talpha_max: 0.143773\tepsilon: 6.88\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.016569\talpha_max: 0.142335\tepsilon: 6.53\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.017003\talpha_max: 0.142335\tepsilon: 6.18\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.013566\talpha_max: 0.140912\tepsilon: 5.83\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.004648\talpha_max: 0.140912\tepsilon: 5.48\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.009808\talpha_max: 0.131753\tepsilon: 5.13\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.004424\talpha_max: 0.131753\tepsilon: 4.73\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.008027\talpha_max: 0.144928\tepsilon: 4.36\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.010100\talpha_max: 0.144928\tepsilon: 3.99\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.004030\talpha_max: 0.159421\tepsilon: 3.63\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002058\talpha_max: 0.159421\tepsilon: 3.21\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.003570\talpha_max: 0.157826\tepsilon: 2.82\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002288\talpha_max: 0.157826\tepsilon: 2.43\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002508\talpha_max: 0.164929\tepsilon: 1.99\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.003066\talpha_max: 0.164929\tepsilon: 1.58\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002002\talpha_max: 0.172350\tepsilon: 1.17\n",
      "Train rounds: 9 [300/60000 (0%)]\tLoss: 0.002729\talpha_max: 0.172350\tepsilon: 0.75\n",
      "Train rounds: 9 [0/60000 (0%)]\tLoss: 0.002654\talpha_max: 0.189585\tepsilon: 0.34\n",
      "\n",
      "Test set: Average loss: 0.1424, Accuracy: 9676/10000 (97%)\tepsilon: -0.03\n",
      "\n",
      "Now is worker 0\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.012853\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.019991\talpha_max: 0.177262\tepsilon: 7.55\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.011521\talpha_max: 0.177262\tepsilon: 7.20\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.009733\talpha_max: 0.165740\tepsilon: 6.85\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.011612\talpha_max: 0.165740\tepsilon: 6.50\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.008888\talpha_max: 0.182314\tepsilon: 6.15\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.003757\talpha_max: 0.182314\tepsilon: 5.80\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.004361\talpha_max: 0.200546\tepsilon: 5.45\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002503\talpha_max: 0.200546\tepsilon: 5.10\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.003090\talpha_max: 0.220600\tepsilon: 4.75\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001644\talpha_max: 0.220600\tepsilon: 4.36\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.000972\talpha_max: 0.242660\tepsilon: 3.99\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001872\talpha_max: 0.242660\tepsilon: 3.63\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.001193\talpha_max: 0.240234\tepsilon: 3.26\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.000379\talpha_max: 0.240234\tepsilon: 2.85\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.000686\talpha_max: 0.264257\tepsilon: 2.46\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.000790\talpha_max: 0.264257\tepsilon: 2.07\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.000793\talpha_max: 0.276149\tepsilon: 1.68\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.000578\talpha_max: 0.276149\tepsilon: 1.29\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.001296\talpha_max: 0.288575\tepsilon: 0.90\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.000343\talpha_max: 0.288575\tepsilon: 0.52\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.000705\talpha_max: 0.317433\tepsilon: 0.04\n",
      "Now is worker 1\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.179503\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.733222\talpha_max: 0.100000\tepsilon: 7.55\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.093776\talpha_max: 0.122212\tepsilon: 7.20\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.629785\talpha_max: 0.122212\tepsilon: 6.85\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.079940\talpha_max: 0.107546\tepsilon: 6.50\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.485725\talpha_max: 0.107546\tepsilon: 6.15\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.021448\talpha_max: 0.106471\tepsilon: 5.80\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.453564\talpha_max: 0.106471\tepsilon: 5.45\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.009823\talpha_max: 0.093694\tepsilon: 5.05\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.269036\talpha_max: 0.093694\tepsilon: 4.63\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.004167\talpha_max: 0.097911\tepsilon: 4.24\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.110619\talpha_max: 0.097911\tepsilon: 3.80\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.003653\talpha_max: 0.091546\tepsilon: 3.39\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.045970\talpha_max: 0.091546\tepsilon: 2.92\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002034\talpha_max: 0.085596\tepsilon: 2.49\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.016289\talpha_max: 0.085596\tepsilon: 1.96\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001920\talpha_max: 0.094155\tepsilon: 1.46\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.005548\talpha_max: 0.094155\tepsilon: 0.97\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002785\talpha_max: 0.093214\tepsilon: 0.48\n",
      "Now is worker 2\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.047130\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.014605\talpha_max: 0.087155\tepsilon: 7.60\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.061422\talpha_max: 0.087155\tepsilon: 7.27\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.026876\talpha_max: 0.091077\tepsilon: 6.89\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.027673\talpha_max: 0.091077\tepsilon: 6.50\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.003313\talpha_max: 0.085157\tepsilon: 6.13\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.011947\talpha_max: 0.085157\tepsilon: 5.76\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.005180\talpha_max: 0.084305\tepsilon: 5.39\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001856\talpha_max: 0.084305\tepsilon: 5.03\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.001497\talpha_max: 0.092736\tepsilon: 4.66\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001656\talpha_max: 0.092736\tepsilon: 4.29\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.003159\talpha_max: 0.102010\tepsilon: 3.92\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002274\talpha_max: 0.102010\tepsilon: 3.51\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.004422\talpha_max: 0.112210\tepsilon: 3.12\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001517\talpha_max: 0.112210\tepsilon: 2.73\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.002351\talpha_max: 0.123432\tepsilon: 2.34\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002245\talpha_max: 0.123432\tepsilon: 1.96\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.004988\talpha_max: 0.128986\tepsilon: 1.57\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001756\talpha_max: 0.128986\tepsilon: 1.18\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.000844\talpha_max: 0.141885\tepsilon: 0.79\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001286\talpha_max: 0.141885\tepsilon: 0.40\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.002423\talpha_max: 0.156073\tepsilon: 0.01\n",
      "Now is worker 3\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.061518\talpha_max: 0.100000\tepsilon: 7.90\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.254593\talpha_max: 0.100000\tepsilon: 7.55\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.023083\talpha_max: 0.171680\tepsilon: 7.20\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.204197\talpha_max: 0.171680\tepsilon: 6.81\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.049147\talpha_max: 0.151079\tepsilon: 6.39\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.051388\talpha_max: 0.151079\tepsilon: 6.00\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.003577\talpha_max: 0.108021\tepsilon: 5.57\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.017961\talpha_max: 0.108021\tepsilon: 5.10\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.007736\talpha_max: 0.118823\tepsilon: 4.66\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.018167\talpha_max: 0.118823\tepsilon: 4.23\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002104\talpha_max: 0.104565\tepsilon: 3.79\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.004147\talpha_max: 0.104565\tepsilon: 3.36\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002924\talpha_max: 0.103519\tepsilon: 2.87\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.001569\talpha_max: 0.103519\tepsilon: 2.30\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002065\talpha_max: 0.113871\tepsilon: 1.78\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.002537\talpha_max: 0.113871\tepsilon: 1.25\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002709\talpha_max: 0.106469\tepsilon: 0.73\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.003428\talpha_max: 0.106469\tepsilon: 0.20\n",
      "Now is worker 4\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.008256\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.266272\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.059841\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.163586\talpha_max: 0.110000\tepsilon: 6.93\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.020808\talpha_max: 0.121000\tepsilon: 6.60\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.098714\talpha_max: 0.121000\tepsilon: 6.27\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.029741\talpha_max: 0.119790\tepsilon: 5.93\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.005660\talpha_max: 0.119790\tepsilon: 5.60\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.004301\talpha_max: 0.125181\tepsilon: 5.22\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.006639\talpha_max: 0.125181\tepsilon: 4.87\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002477\talpha_max: 0.103274\tepsilon: 4.52\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.002173\talpha_max: 0.103274\tepsilon: 4.12\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.003039\talpha_max: 0.090881\tepsilon: 3.71\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.007944\talpha_max: 0.090881\tepsilon: 3.32\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002176\talpha_max: 0.089972\tepsilon: 2.88\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.002421\talpha_max: 0.089972\tepsilon: 2.42\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.003651\talpha_max: 0.094021\tepsilon: 1.99\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.002427\talpha_max: 0.094021\tepsilon: 1.55\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001796\talpha_max: 0.087910\tepsilon: 1.12\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.003762\talpha_max: 0.087910\tepsilon: 0.68\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002379\talpha_max: 0.087031\tepsilon: 0.25\n",
      "Now is worker 5\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.176268\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.273813\talpha_max: 0.100000\tepsilon: 7.60\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.052092\talpha_max: 0.110000\tepsilon: 7.27\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.067664\talpha_max: 0.110000\tepsilon: 6.93\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.074928\talpha_max: 0.121000\tepsilon: 6.56\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.040671\talpha_max: 0.121000\tepsilon: 6.21\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.024586\talpha_max: 0.119790\tepsilon: 5.86\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.039499\talpha_max: 0.119790\tepsilon: 5.51\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.014536\talpha_max: 0.131769\tepsilon: 5.11\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.016553\talpha_max: 0.131769\tepsilon: 4.74\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.006279\talpha_max: 0.144946\tepsilon: 4.37\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.005997\talpha_max: 0.144946\tepsilon: 4.01\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.008795\talpha_max: 0.159440\tepsilon: 3.64\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.003720\talpha_max: 0.159440\tepsilon: 3.27\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.003475\talpha_max: 0.175385\tepsilon: 2.90\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.003665\talpha_max: 0.175385\tepsilon: 2.53\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001928\talpha_max: 0.192923\tepsilon: 2.16\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.001994\talpha_max: 0.192923\tepsilon: 1.80\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002701\talpha_max: 0.190994\tepsilon: 1.43\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.003301\talpha_max: 0.190994\tepsilon: 1.06\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002342\talpha_max: 0.168075\tepsilon: 0.69\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.001570\talpha_max: 0.168075\tepsilon: 0.29\n",
      "Now is worker 6\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.376943\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.149956\talpha_max: 0.100000\tepsilon: 7.56\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.284027\talpha_max: 0.137275\tepsilon: 7.21\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.059784\talpha_max: 0.137275\tepsilon: 6.86\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.030363\talpha_max: 0.135902\tepsilon: 6.51\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.086155\talpha_max: 0.135902\tepsilon: 6.16\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.020485\talpha_max: 0.149492\tepsilon: 5.77\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.019187\talpha_max: 0.149492\tepsilon: 5.40\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.030971\talpha_max: 0.164442\tepsilon: 4.93\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.019908\talpha_max: 0.164442\tepsilon: 4.52\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.021317\talpha_max: 0.171841\tepsilon: 4.11\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.015758\talpha_max: 0.171841\tepsilon: 3.70\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.003533\talpha_max: 0.141769\tepsilon: 3.28\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.012388\talpha_max: 0.141769\tepsilon: 2.82\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.002820\talpha_max: 0.148149\tepsilon: 2.39\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.002599\talpha_max: 0.148149\tepsilon: 1.95\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.001365\talpha_max: 0.162964\tepsilon: 1.52\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.002342\talpha_max: 0.162964\tepsilon: 1.08\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.000944\talpha_max: 0.179260\tepsilon: 0.58\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.001636\talpha_max: 0.179260\tepsilon: 0.12\n",
      "Now is worker 7\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.124870\talpha_max: 0.100000\tepsilon: 7.93\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.188448\talpha_max: 0.177467\tepsilon: 7.56\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.091212\talpha_max: 0.177467\tepsilon: 7.17\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.051209\talpha_max: 0.175693\tepsilon: 6.80\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.034673\talpha_max: 0.175693\tepsilon: 6.43\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.012782\talpha_max: 0.193262\tepsilon: 6.06\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.007552\talpha_max: 0.193262\tepsilon: 5.70\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.006923\talpha_max: 0.201959\tepsilon: 5.28\n",
      "Train rounds: 10 [0/60000 (0%)]\tLoss: 0.007015\talpha_max: 0.201959\tepsilon: 4.89\n",
      "Train rounds: 10 [300/60000 (0%)]\tLoss: 0.002107\talpha_max: 0.177724\tepsilon: 4.50\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "# model = Net().to(device)\n",
    "args.best_lr_list = []\n",
    "\n",
    "args.alpha_max = args.init_alpha_max\n",
    "args.epsilon = 8\n",
    "p_ng, p_nmax = args.epsilon / (2 * args.split), args.epsilon / (2 * args.split) \n",
    "# for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# for client in workers\n",
    "#     while epsilon is over 0, keep training\n",
    "server_model = Net().to(device)\n",
    "temp_model = Net().to(device)\n",
    "\n",
    "logdir = \"/root/notebooks/tensorflow/logs/DPAGD/F_DPAGD_v2\"\n",
    "writer = SummaryWriter(logdir)\n",
    "\n",
    "for r in range(args.rounds):\n",
    "    temp_model_list = []\n",
    "    # set model into model list\n",
    "    server_model_list = set_model_list(args, server_model, Net)\n",
    "    \n",
    "    \n",
    "    #train on all the client\n",
    "    for worker_index, (worker, model) in enumerate(zip(workers, server_model_list)):\n",
    "        print(\"Now is worker {}\".format(worker_index))\n",
    "        \n",
    "        args.alpha_max = args.init_alpha_max\n",
    "        args.epsilon = 8\n",
    "        p_ng = args.epsilon / (2 * args.split)\n",
    "        del args.best_lr_list[:]\n",
    "        \n",
    "        while args.epsilon > 0:\n",
    "            worker_best_model, p_ng = train(args, device, model, train_loader , r, worker_index, p_ng)\n",
    "        #append model trained by client into list\n",
    "        temp_model.load_state_dict(worker_best_model.state_dict())\n",
    "        temp_model_list.append(temp_model)\n",
    "        \n",
    "    temp_stat_dict = aggregate_model(args, temp_model_list)\n",
    "    server_model.load_state_dict(temp_stat_dict)\n",
    "    test(args, device, server_model, test_loader, r, writer)\n",
    "    \n",
    "\n",
    "print(\"Spend time:{:.1f}\".format(time.time() - start))\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
